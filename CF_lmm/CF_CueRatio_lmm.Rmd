---
title: "CF_CueRatio_lmm"
author: "Haiyang Jin (hjin317@aucklanduni.ac.nz)"
date: "`r format(Sys.time(), '%d-%m-%Y')`"
output: 
  pdf_document:
    number_sections: true
    toc: true
version: "1.0"
---


# Preparations
```{r setup and load the related libraries, include=FALSE}
## set chunk options
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(include = TRUE)
knitr::opts_chunk$set(warning = FALSE)
# knitr::opts_chunk$set(fig.width=7, fig.asp =0.618) 
# knitr::opts_chunk$set(comment = "#") # (NA, to remove all hashes)

## load libraries
# libraries for cleaning data
library(tidyverse)
library(readxl)
library(lme4)
library(lmerTest)
library(optimx)
library(emmeans)

folder_lmm <- "lmm_output"

```


## Load data 
```{r read the data file}

# list filenames
file1_list <- list.files(file.path("data", "1"), pattern = "*.xlsx", full.names = TRUE)
file2_list <- list.files(file.path("data", "2"), pattern = "*.xlsx", full.names = TRUE)

# load data
df_raw_E1 <- sapply(file1_list, read_excel, na = "NA", simplify = FALSE) %>% bind_rows(.id = "id") 
df_raw_E2 <- sapply(file2_list, read_excel, na = "NA", simplify = FALSE) %>% bind_rows(.id = "id")
  

# combine data from the two experiments
df_raw_E1_temp <- df_raw_E1 %>% 
  select(-c(SubTrial)) %>% 
  mutate(Probability = 0.5,
         targetDuration = 999,
         Participant = Participant + 100)

df_raw_E2_temp <- df_raw_E2 %>% 
  select(-c(Age, Gender, Ethnicity, Block, FaceIndex)) %>% 
  mutate(Participant = Participant + 200,
         Probability = if_else(grepl("75TopCue", Experiment), 0.75, 0.25))

df_raw <- bind_rows(df_raw_E1_temp, df_raw_E2_temp)
  
df_raw

```

## Tidy data

```{r select certain rows and columns from the data, and calculate the Z value for reaction times}

df_tidy <- df_raw %>% 
  filter(!is.na(isCorrect)) %>%  # remove NA trials
  mutate(Cue = if_else(CuedHalf == "T", "top", "bottom"),
         Congruency = if_else(Congruency == "C", "congruent", "incongruent"),
         Alignment = if_else(Alignment == "A", "aligned", "misaligned"),
         SameDifferent = if_else(SameDifferent == "S", "same", "different"),
         Participant = as_factor(Participant),
         Cue = factor(Cue, levels = c("top", "bottom")),
         Congruency = as_factor(Congruency),
         Alignment = as_factor(Alignment),
         SameDifferent = factor(SameDifferent, levels = c("same", "different")),
         Probability = as_factor(Probability))

```

+ Cue: top vs. bottom
+ Congruency: congruent vs. incongruent
+ Alignment: aligned vs. misaligned
+ SameDifferent: same vs. different

```{r}
# set successive difference coding for fixed effects
contrasts(df_tidy$Cue) <- MASS::contr.sdif(nlevels(df_tidy$Cue)) 
contrasts(df_tidy$Congruency) <- MASS::contr.sdif(nlevels(df_tidy$Congruency)) 
contrasts(df_tidy$Alignment) <- MASS::contr.sdif(nlevels(df_tidy$Alignment))
contrasts(df_tidy$SameDifferent) <- MASS::contr.sdif(nlevels(df_tidy$SameDifferent))

# set successive difference coding for random effects
df_lmm <- df_tidy %>% 
  mutate(
    Con_C = if_else(Congruency == "congruent", -.5, .5),
    Ali_C = if_else(Alignment == "aligned", -.5, .5),
    Sam_C = if_else(SameDifferent == "same", -.5, .5),
    
    Con_Ali = Con_C * Ali_C,
    Con_Sam = Con_C * Sam_C,
    Ali_Sam = Ali_C * Sam_C,
    
    Con_Ali_Sam = Con_Ali * Sam_C
  )

# save the data (for fitting model in cluster)
save(df_lmm, file = file.path("data", "df_lmm.RData"))

```


# Responses (d')
## Fitting the generalized mixed models
### The maximal model
```{r resp max}

file_resp_max <- file.path(folder_lmm, "Resp_lmm_max.RData")

# fit the max model
if (!file.exists(file_resp_max)) {
  glmm_resp_max <- glmer(
    isCorrect ~ Cue * Congruency * Alignment * SameDifferent + Probability + 
      (Congruency * Alignment * SameDifferent | Participant), # Con_Ali_Sam
    family = binomial(link = "probit"),
    data = df_lmm,
    control = glmerControl(optimizer = "optimx", # calc.derivs = FALSE,
                           optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE))
  )

  save(glmm_resp_max, file = file_resp_max)
} else {
  load(file_resp_max)
}

print(summary(glmm_resp_max), corr = FALSE)

```

### The zero-correlation-parameter model
```{r resp zcp}

file_resp_zcp <- file.path(folder_lmm, "Resp_lmm_zcp.RData")

# fit the zcp model
if (!file.exists(file_resp_zcp)) {
  glmm_resp_zcp <- glmer(
    isCorrect ~ Cue * Congruency * Alignment * SameDifferent + Probability + 
      (Con_C + Ali_C + Sam_C + 
         Con_Ali + Con_Sam + Ali_Sam +
         Con_Ali_Sam || Participant),
    family = binomial(link = "probit"),
    data = df_lmm,
    control = glmerControl(optimizer = "optimx", # calc.derivs = FALSE,
                           optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE))
  )
  
  # save(glmm_resp_zcp, file = file_resp_zcp)
} else {
  load(file_resp_zcp)
}

print(summary(glmm_resp_zcp), corr = FALSE)

```

### The reduced model
```{r PCA analysis for resp zcp lmm}
summary(rePCA(glmm_resp_zcp))
```

```{r resp reduced}
file_resp_rdc <- file.path(folder_lmm, "Resp_lmm_rdc.RData")

# fit the zcp model
if (!file.exists(file_resp_rdc)) {
  glmm_resp_rdc <- glmer(
    isCorrect ~ Cue * Congruency * Alignment * SameDifferent + Probability + 
      (Con_C + Sam_C + # Ali_C + 
         Con_Ali + Con_Sam + Ali_Sam # +
       || Participant), # Con_Ali_Sam
    family = binomial(link = "probit"),
    data = df_lmm,
    control = glmerControl(optimizer = "optimx", # calc.derivs = FALSE,
                           optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE))
  )
  
  # save(glmm_resp_rdc, file = file_resp_rdc)
} else {
  load(file_resp_rdc)
}

print(summary(glmm_resp_rdc), corr = FALSE)
```

### The extended model
```{r resp exteded model}
file_resp_etd <- file.path(folder_lmm, "Resp_lmm_etd.RData")

# fit the etd model
if (!file.exists(file_resp_etd)) {
  glmm_resp_etd <- glmer(
    isCorrect ~ Cue * Congruency * Alignment * SameDifferent + Probability + 
      (Con_C + Sam_C + # Ali_C + 
         Con_Ali + Con_Sam + Ali_Sam # +
       | Participant), # Con_Ali_Sam
    family = binomial(link = "probit"),
    data = df_lmm,
    control = glmerControl(optimizer = "optimx", # calc.derivs = FALSE,
                           optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE))
  )
  
  # save(glmm_resp_etd, file = glmm_resp_etd)
} else {
  load(file_resp_etd)
}

print(summary(glmm_resp_etd), corr = FALSE)
```

### The optimal model

```{r comapre etd and rdc}
# compare the extended and reduced model
anova(glmm_resp_etd, glmm_resp_rdc, refit = FALSE)
```

According to BIC, the extended model (`glmm_resp_etd`) explained the data better than the reduced model (`glmm_resp_rdc`) and, therefore, the extended model is used as the optimal model.

```{r the optimal model}
glmm_resp_opt <- glmm_resp_etd

print(summary(glmm_resp_opt), corr = FALSE)
```


## Estimated marginal means
### Estimated marginal means for hit and correct rejection
```{r emm}
emm_resp <- emmeans(glmm_resp_opt, ~ Cue + Congruency + Alignment + SameDifferent)

emm_resp

```

### Estimated marginal means for d'





