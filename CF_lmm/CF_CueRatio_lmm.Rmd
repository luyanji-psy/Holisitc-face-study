---
title: "CF_CueRatio_lmm"
author: "[Haiyang Jin](https://haiyangjin.github.io/)"
date: "`r format(Sys.time(), '%d-%m-%Y')`"
output: 
  html_document:
    number_sections: true
    toc: true
    toc_float: true
version: "1.0"
---

<style>
pre {
  overflow-x: auto;
}
pre code {
  word-wrap: normal;
  white-space: pre;
}
</style>

```{r global_options, echo = FALSE, include = FALSE}
options(width = 3000)
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE,
                      cache = FALSE, tidy = FALSE, size = "small")
```

# Preparations
```{r setup and load the related libraries, include=FALSE}
## set chunk options
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(include = TRUE)
knitr::opts_chunk$set(warning = FALSE)
# options(width = 1800)
# knitr::opts_chunk$set(fig.width=7, fig.asp =0.618) 
# knitr::opts_chunk$set(comment = "#") # (NA, to remove all hashes)

## load libraries
# libraries for cleaning data
library(tidyverse)
library(lme4)
library(lmerTest)
library(optimx)
library(emmeans)

folder_lmm <- "lmm_output"
ylimit_cf_d <- c(-.5, 3.2)
ylimit_cf_fi_d <- c(-1.1, 1.1)
ylimit_cf_rt <- c(650, 1150)
ylimit_cf_fi_rt <- c(-100, 100)
```


## Load data 
```{r read the data file}

# list filenames
file1_list <- list.files(file.path("data", "1"), pattern = "*.xlsx", full.names = TRUE)
file2_list <- list.files(file.path("data", "2"), pattern = "*.xlsx", full.names = TRUE)

# load data
df_raw_E1 <- sapply(file1_list, read_excel, na = "NA", simplify = FALSE) %>% bind_rows(.id = "id") 
df_raw_E2 <- sapply(file2_list, read_excel, na = "NA", simplify = FALSE) %>% bind_rows(.id = "id")
  

# combine data from the two experiments
df_raw_E1_temp <- df_raw_E1 %>% 
  select(-c(SubTrial)) %>% 
  mutate(Probability = 0.5,
         targetDuration = 200, # fix a bug in exp
         Participant = Participant + 100)

df_raw_E2_temp <- df_raw_E2 %>% 
  select(-c(Age, Gender, Ethnicity, Block, FaceIndex)) %>% 
  mutate(Participant = Participant + 200,
         Probability = if_else(grepl("75TopCue", Experiment), 0.75, 0.25))

df_raw <- bind_rows(df_raw_E1_temp, df_raw_E2_temp)
  
str(df_raw)
```

## Tidy data

```{r select certain rows and columns from the data, and calculate the Z value for reaction times}

df_tidy <- df_raw %>% 
  filter(!is.na(thisResponse)) %>%  # remove NA trials based on responses
  mutate(Cue = if_else(CuedHalf == "T", "top", "bottom"),
         Congruency = if_else(Congruency == "C", "congruent", "incongruent"),
         Alignment = if_else(Alignment == "A", "aligned", "misaligned"),
         SameDifferent = if_else(SameDifferent == "S", "same", "different"),
         Participant = as_factor(Participant),
         Cue = factor(Cue, levels = c("top", "bottom")),
         Congruency = factor(Congruency, levels = c("congruent", "incongruent")),
         Alignment = as_factor(Alignment),
         SameDifferent = factor(SameDifferent, levels = c("same", "different")),
         Probability = as_factor(Probability),
         Resp = if_else(thisResponse == "S", 1, 0),
         RT = round(reactionTime * 1000+200)) # plus the duration of target faces

```

+ Cue: top vs. bottom
+ Congruency: congruent vs. incongruent
+ Alignment: aligned vs. misaligned
+ SameDifferent: same vs. different


```{r}
# Trial numbers in each condition
df_tidy %>% 
  group_by(Participant) %>% 
  summarize(nTotal = n()) 

# For 3 participants in E1, one trail was removed due to no response recorded.
```


```{r}
# set successive difference coding for fixed effects
contrasts(df_tidy$Cue) <- MASS::contr.sdif(nlevels(df_tidy$Cue)) 
contrasts(df_tidy$Congruency) <- MASS::contr.sdif(nlevels(df_tidy$Congruency)) 
contrasts(df_tidy$Alignment) <- MASS::contr.sdif(nlevels(df_tidy$Alignment))
contrasts(df_tidy$SameDifferent) <- MASS::contr.sdif(nlevels(df_tidy$SameDifferent))

# set successive difference coding for random effects
df_lmm <- df_tidy %>% 
  mutate(
    Cue_C = if_else(Cue == "top", -.5, .5),
    Con_C = if_else(Congruency == "congruent", -.5, .5),
    Ali_C = if_else(Alignment == "aligned", -.5, .5),
    Sam_C = if_else(SameDifferent == "same", -.5, .5),
    
    Cue_Con = Cue_C * Con_C,
    Cue_Ali = Cue_C * Ali_C,
    Cue_Sam = Cue_C * Sam_C,
    Con_Ali = Con_C * Ali_C,
    Con_Sam = Con_C * Sam_C,
    Ali_Sam = Ali_C * Sam_C,
    
    Cue_Con_Ali = Cue_Con * Ali_C,
    Cue_Con_Sam = Cue_Con * Sam_C,
    Cue_Ali_Sam = Cue_Ali * Sam_C,
    Con_Ali_Sam = Con_Ali * Sam_C,
    
    Cue_Con_Ali_Sam = Cue_Con_Ali * Sam_C
  )

# save the data (for fitting model in cluster)
# save(df_lmm, file = file.path("data", "df_lmm.RData"))

```


# Experiment 1
```{r only keep E1}
df_lmm_E1 <- df_lmm %>% 
  filter(Experiment == "109_cue") %>% 
  droplevels()

# save(df_lmm_E1, file = file.path("data", "df_lmm_E1.RData"))
nlevels(df_lmm_E1$Participant)
```

## Response (d')
### Fitting the generalized mixed models
#### The maximal model
```{r resp max d E1}

# file_E1_resp_max <- file.path(folder_lmm, "E1_Resp_lmm_max.RData")
# 
# # fit the max model
# if (!file.exists(file_E1_resp_max)) {
#   glmm_E1_resp_max <- glmer(
#     Resp ~ Cue * Congruency * Alignment * SameDifferent + 
#       (Cue * Congruency * Alignment * SameDifferent | Participant), # Con_Ali_Sam
#     family = binomial(link = "probit"),
#     data = df_lmm_E1,
#     control = glmerControl(optimizer = "optimx", # calc.derivs = FALSE,
#                            optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE))
#   )
# 
#   save(glmm_E1_resp_max, file = file_E1_resp_max)
# } else {
#   load(file_E1_resp_max)
# }
# 
# print(summary(glmm_E1_resp_max), corr = FALSE)

```

#### The zero-correlation-parameter model
```{r resp zcp E1}
file_E1_resp_zcp <- file.path(folder_lmm, "E1_Resp_lmm_zcp.RData")

# fit the zcp model
if (!file.exists(file_E1_resp_zcp)) {
  glmm_E1_resp_zcp <- glmer(
    Resp ~ Cue * Congruency * Alignment * SameDifferent + 
      (Cue_C + Con_C + Ali_C + Sam_C + 
         Cue_Con + Cue_Ali + Cue_Sam + Con_Ali + Con_Sam + Ali_Sam +
         Cue_Con_Ali + Cue_Con_Sam + Cue_Ali_Sam + Con_Ali_Sam + 
         Cue_Con_Ali_Sam || Participant),
    family = binomial(link = "probit"),
    data = df_lmm_E1,
    control = glmerControl(optimizer = "optimx", # calc.derivs = FALSE,
                           optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE))
  )
  
  # save(glmm_E1_resp_zcp, file = file_E1_resp_zcp)
} else {
  load(file_E1_resp_zcp)
}

print(summary(glmm_E1_resp_zcp), corr = FALSE)
```

#### The reduced model
```{r PCA analysis for resp zcp lmm E1}
summary(rePCA(glmm_E1_resp_zcp))
```

`Con_Ali`, `Cue_Con_Ali`, `Ali_Sam`, and `Con_C` were removed from extended model (`glmm_E1_resp_zcp`) due to that the variances they explained were smaller than 0.1%, making `glmm_resp_rdc`.

```{r resp rdc E1}
file_E1_resp_rdc <- file.path(folder_lmm, "E1_Resp_lmm_rdc.RData")

# fit the rdc model
if (!file.exists(file_E1_resp_rdc)) {
  glmm_E1_resp_rdc <- glmer(
    Resp ~ Cue * Congruency * Alignment * SameDifferent + 
      (Cue_C + Ali_C + Sam_C + # Con_C + 
         Cue_Con + Cue_Ali + Cue_Sam + Con_Sam + # Con_Ali + Ali_Sam + 
         Cue_Con_Sam + Cue_Ali_Sam + Con_Ali_Sam + # Cue_Con_Ali + 
         Cue_Con_Ali_Sam || Participant),
    family = binomial(link = "probit"),
    data = df_lmm_E1,
    control = glmerControl(optimizer = "optimx", # calc.derivs = FALSE,
                           optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE))
  )
  
  # save(glmm_E1_resp_rdc, file = file_E1_resp_rdc)
} else {
  load(file_E1_resp_rdc)
}

print(summary(glmm_E1_resp_rdc), corr = FALSE)
```

#### The extended model
```{r resp etd E1}
file_E1_resp_etd <- file.path(folder_lmm, "E1_Resp_lmm_etd.RData")

# fit the etd model
if (!file.exists(file_E1_resp_etd)) {
  glmm_E1_resp_etd <- glmer(
    Resp ~ Cue * Congruency * Alignment * SameDifferent + 
      (Cue_C + Ali_C + Sam_C + # Con_C + 
         Cue_Con + Cue_Ali + Cue_Sam + Con_Sam + # Con_Ali + Ali_Sam + 
         Cue_Con_Sam + Cue_Ali_Sam + Con_Ali_Sam + # Cue_Con_Ali + 
         Cue_Con_Ali_Sam | Participant),
    family = binomial(link = "probit"),
    data = df_lmm_E1,
    control = glmerControl(optimizer = "optimx", # calc.derivs = FALSE,
                           optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE))
  )
  
  # save(glmm_E1_resp_etd, file = file_E1_resp_etd)
} else {
  load(file_E1_resp_etd)
}

print(summary(glmm_E1_resp_etd), corr = FALSE)
```

```{r}
summary(rePCA(glmm_E1_resp_etd))
```

`Cue_Con`, `Ali_C`, `Cue_Ali`, and `Intercept` were removed from extended model.

```{r resp etd1 E1}
file_E1_resp_etd1 <- file.path(folder_lmm, "E1_Resp_lmm_etd1.RData")

# fit the etd1 model
if (!file.exists(file_E1_resp_etd1)) {
  glmm_E1_resp_etd1 <- glmer(
    Resp ~ Cue * Congruency * Alignment * SameDifferent + 
      (0 + Cue_C + Sam_C + # Con_C + Ali_C + 
         Cue_Sam + Con_Sam + # Con_Ali + Ali_Sam + Cue_Con + Cue_Ali + 
         Cue_Con_Sam + Cue_Ali_Sam + Con_Ali_Sam + # Cue_Con_Ali + 
         Cue_Con_Ali_Sam | Participant),
    family = binomial(link = "probit"),
    data = df_lmm_E1,
    control = glmerControl(optimizer = "optimx", # calc.derivs = FALSE,
                           optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE))
  )
  
  # save(glmm_E1_resp_etd1, file = file_E1_resp_etd1)
} else {
  load(file_E1_resp_etd1)
}

print(summary(glmm_E1_resp_etd1), corr = FALSE)
```

```{r}
summary(rePCA(glmm_E1_resp_etd1))
```

`Cue_Ali_Sam`, and `Cue_C` were removed from extended1 model.

```{r resp etd2 E1}
file_E1_resp_etd2 <- file.path(folder_lmm, "E1_Resp_lmm_etd2.RData")

# fit the etd2 model
if (!file.exists(file_E1_resp_etd2)) {
  glmm_E1_resp_etd2 <- glmer(
    Resp ~ Cue * Congruency * Alignment * SameDifferent + 
      (0 + Sam_C + # Con_C + Ali_C + Cue_C + 
         Cue_Sam + Con_Sam + # Con_Ali + Ali_Sam + Cue_Con + Cue_Ali + 
         Cue_Con_Sam + Con_Ali_Sam + # Cue_Con_Ali + Cue_Ali_Sam + 
         Cue_Con_Ali_Sam | Participant),
    family = binomial(link = "probit"),
    data = df_lmm_E1,
    control = glmerControl(optimizer = "optimx", # calc.derivs = FALSE,
                           optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE))
  )
  # save(glmm_E1_resp_etd2, file = file_E1_resp_etd2)
} else {
  load(file_E1_resp_etd2)
}

print(summary(glmm_E1_resp_etd2), corr = FALSE)
```

```{r}
summary(rePCA(glmm_E1_resp_etd2))
```
`Con_Ali_Sam` was removed from extended2 model.

```{r resp etd3 E1}
file_E1_resp_etd3 <- file.path(folder_lmm, "E1_Resp_lmm_etd3.RData")

# fit the etd3 model
if (!file.exists(file_E1_resp_etd3)) {
  glmm_E1_resp_etd3 <- glmer(
    Resp ~ Cue * Congruency * Alignment * SameDifferent + 
      (0 + Sam_C + # Con_C + Ali_C + Cue_C + 
         Cue_Sam + Con_Sam + # Con_Ali + Ali_Sam + Cue_Con + Cue_Ali + 
         Cue_Con_Sam + # Cue_Con_Ali + Cue_Ali_Sam + Con_Ali_Sam + 
         Cue_Con_Ali_Sam | Participant),
    family = binomial(link = "probit"),
    data = df_lmm_E1,
    control = glmerControl(optimizer = "optimx", # calc.derivs = FALSE,
                           optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE))
  )
  # save(glmm_E1_resp_etd3, file = file_E1_resp_etd3)
} else {
  load(file_E1_resp_etd3)
}

print(summary(glmm_E1_resp_etd3), corr = FALSE)
```

```{r}
summary(rePCA(glmm_E1_resp_etd3))
```
`Sam_C` was removed from extended3 model.

```{r resp etd4 E1}
file_E1_resp_etd4 <- file.path(folder_lmm, "E1_Resp_lmm_etd4.RData")

# fit the etd4 model
if (!file.exists(file_E1_resp_etd4)) {
  glmm_E1_resp_etd4 <- glmer(
    Resp ~ Cue * Congruency * Alignment * SameDifferent + 
      (0 + # Con_C + Ali_C + Cue_C + Sam_C + 
         Cue_Sam + Con_Sam + # Con_Ali + Ali_Sam + Cue_Con + Cue_Ali + 
         Cue_Con_Sam + # Cue_Con_Ali + Cue_Ali_Sam + Con_Ali_Sam + 
         Cue_Con_Ali_Sam | Participant),
    family = binomial(link = "probit"),
    data = df_lmm_E1,
    control = glmerControl(optimizer = "optimx", # calc.derivs = FALSE,
                           optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE))
  )
  # save(glmm_E1_resp_etd4, file = file_E1_resp_etd4)
} else {
  load(file_E1_resp_etd4)
}

print(summary(glmm_E1_resp_etd4), corr = FALSE)
```

```{r}
summary(rePCA(glmm_E1_resp_etd4))
```
`Con_Sam` was removed from extended4 model.

```{r resp etd5 E1}
file_E1_resp_etd5 <- file.path(folder_lmm, "E1_Resp_lmm_etd5.RData")

# fit the etd5 model
if (!file.exists(file_E1_resp_etd5)) {
  glmm_E1_resp_etd5 <- glmer(
    Resp ~ Cue * Congruency * Alignment * SameDifferent + 
      (0 + # Con_C + Ali_C + Cue_C + Sam_C + 
         Cue_Sam + # Con_Ali + Ali_Sam + Cue_Con + Cue_Ali + Con_Sam + 
         Cue_Con_Sam + # Cue_Con_Ali + Cue_Ali_Sam + Con_Ali_Sam + 
         Cue_Con_Ali_Sam | Participant),
    family = binomial(link = "probit"),
    data = df_lmm_E1,
    control = glmerControl(optimizer = "optimx", # calc.derivs = FALSE,
                           optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE))
  )
  # save(glmm_E1_resp_etd5, file = file_E1_resp_etd5)
} else {
  load(file_E1_resp_etd5)
}

print(summary(glmm_E1_resp_etd5), corr = FALSE)
```

#### The optimal model
```{r comapre etd and rdc E1 d}
# compare the extended and reduced model
anova(glmm_E1_resp_etd5, glmm_E1_resp_rdc, refit = FALSE)
```

According to BIC, the reduced model (`glmm_resp_rdc`) explained the data better than the extended model (`glmm_resp_etd5`) and, therefore, the reduced model is used as the optimal model.

```{r the optimal model E1 d}
glmm_E1_resp_opt <- glmm_E1_resp_rdc

print(summary(glmm_E1_resp_opt), corr = FALSE)
```

### Estimated marginal means
#### Estimated marginal means for hit and false alarm
```{r emm E1 resp}
(emm_E1_resp <- emmeans(glmm_E1_resp_opt, ~ Alignment + Congruency + Cue + SameDifferent))
```

#### Estimated marginal means for d'
```{r message=FALSE}
emm_E1_d <- contrast(emm_E1_resp, method = "pairwise", simple = "SameDifferent")
summary(emm_E1_d[1:8], infer = c(TRUE, FALSE))

# quick check (uncorrected)
# emmip(emm_E1_d, Congruency ~ Alignment | Cue, CIs = TRUE) 
```


```{r plot for publication E1 d slides, fig.width=3, fig.asp=.6}
plot_E1_cf_d <- summary(emm_E1_d[1:8], infer = c(TRUE, FALSE)) %>% 
  as_tibble() %>% 
  ggplot(aes(y = estimate, x = Alignment, color = Congruency, group = Congruency)) +
  geom_point(position = position_dodge(width = 0.1), size = 2) +
  geom_line(aes(linetype = Congruency), position = position_dodge(width = 0.1),
            size = 0.8) +
  scale_linetype_manual(values=c("solid", "dashed"))+
  geom_errorbar(aes(ymin = asymp.LCL, ymax = asymp.UCL), size=1.5, width=0, 
                alpha = .6, position = position_dodge(width = 0.1),
                show.legend = F) + 
  facet_grid(. ~Cue, switch = "both") +
  coord_cartesian(ylim = ylimit_cf_d) +  # set the limit for y axis c(0, 1100)
  labs(x = "Cues", y = expression("Sensitivity"~italic("d'")), fill = "Congruency") +  # set the names for main, x and y axises
  geom_text(label = c("***", "", "", "", "*", "", "", ""), color = "red", size = 6, nudge_y = 0.5, nudge_x = 0.5) + # add starts to the significant columns
  theme_bw() +
  theme(
    text = element_text(size = 10),
    axis.title = element_text(size = 16), 
    axis.text = element_text(size = 14), # the size of the texts in plot
    # axis.text.x = element_text(angle = 45, vjust = 0.5),
    legend.title=element_text(size=15),
    legend.text=element_text(size=14),
    legend.position = "right",
    legend.key.width = unit(1.2, "cm"),
    plot.title = element_text(lineheight=.8, face="bold", size = 17),
    panel.border = element_blank(),
    panel.grid.minor = element_blank(),
    panel.grid.major = element_blank(),
    axis.line.x = element_line(colour = 'black', size=0.5, linetype='solid'),
    axis.line.y = element_line(colour = 'black', size=0.5, linetype='solid'),
    # remove the facet background color
    strip.text = element_text(face="bold", size=14, lineheight=5.0),
    strip.background = element_rect(fill="white", colour="white", size=1),
    strip.placement = "outside"
  ) 

# ggsave(filename = "E1_cf_d.pdf", plot_E1_cf_d, width = 8, height = 4.8)

plot_E1_cf_d
```

```{r plot for publication E1 d paper, fig.width=3, fig.asp=.6}
# ggsave(filename = "E1_cf_d.pdf", 
#        plot_E1_cf_d +
#          theme(legend.position=c(0.5, 0.15)), 
#        width = 7)
```


#### Composite effects
Composite face effects for top and bottom parts:
```{r message=FALSE}
emm_E1_d_cf <- contrast(emm_E1_resp, interaction = "pairwise", by = "Cue")
summary(emm_E1_d_cf[1:2], infer = TRUE)
```

#### Facilitation and interference
```{r message=FALSE}
# Sensitivity d'
emm_E1_d_fi <- contrast(emm_E1_resp, interaction = "pairwise", by = c("Cue", "Congruency"), adjust = "Tukey")
summary(emm_E1_d_fi[1:4], infer=TRUE)

# # showing the differences between aligned and misaligned (aligned-misaligned)
# emmip(emm_E1_d_fi[1:4], ~ Cue | Congruency, CIs = TRUE, adjust = "Tukey") +
#   geom_hline(yintercept = 0, linetype = "dashed")
```

```{r fi E1 d, fig.width=6, fig.asp=.65}
plot_E1_cffi_d <- summary(emm_E1_d_fi[1:4], infer=TRUE) %>% 
  as_tibble() %>% 
  ggplot(aes(y = estimate, x = Cue, color = Congruency)) +
  geom_point(size = 2) +
  geom_errorbar(aes(ymin = asymp.LCL, ymax = asymp.UCL), size=1.5, width=0, 
                alpha = .6) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  facet_grid(. ~ Congruency, switch = "both") +
  coord_cartesian(ylim = ylimit_cf_fi_d) +  # set the limit for y axis c(0, 1100)
  labs(x = "Congruency", y = expression(italic("d'")~"(aligned-misaligned)")) +  # set the names for main, x and y axises
  theme_bw() +
  theme(
    text = element_text(size = 10),
    axis.title = element_text(size = 16), 
    axis.text = element_text(size = 14), # the size of the texts in plot
    # axis.text.x = element_text(angle = 45, vjust = 0.5),
    legend.title=element_text(size=15),
    legend.text=element_text(size=14),
    legend.position = "none",
    legend.key.width = unit(1.2, "cm"),
    plot.title = element_text(lineheight=.8, face="bold", size = 17),
    panel.border = element_blank(),
    panel.grid.minor = element_blank(),
    panel.grid.major = element_blank(),
    axis.line.x = element_line(colour = 'black', size=0.5, linetype='solid'),
    axis.line.y = element_line(colour = 'black', size=0.5, linetype='solid'),
    # remove the facet background color
    strip.text = element_text(face="bold", size=14, lineheight=5.0),
    strip.background = element_rect(fill="white", colour="white", size=1),
    strip.placement = "outside"
  ) +
  NULL

# ggsave(filename = "E1_fi_d.pdf", plot_E1_cffi_d, width = 7, height = 4.55)

plot_E1_cffi_d
```

```{r message=FALSE}
# Sensitivity d'
test <- contrast(emm_E1_resp, method ="pairwise", simple = "Alignment", adjust = "Tukey")
test[1:8]
```

## Response times
```{r only keep correct trials (but with both same and different trials) E1}
df_lmm_E1_rt <- df_lmm_E1 %>% 
  filter(isCorrect == 1)

# save(df_lmm_E1_rt, file = file.path("data", "df_lmm_E1_rt.RData"))
```

### Fitting the generalized mixed models
with log-transformation.
#### The maximal model
```{r E1 rt max}
# file_E1_rt_max <- file.path(folder_lmm, "E1_rt_lmm_max.RData")
# 
# # fit the max model
# if (!file.exists(file_E1_rt_max)) {
#   glmm_E1_rt_max <- glmer(
#     log(RT) ~ Cue * Congruency * Alignment + 
#       (Cue * Congruency * Alignment | Participant), 
#     family = lognormal(),
#     data = df_lmm_rt,
#     control = glmerControl(optimizer = "optimx", # calc.derivs = FALSE,
#                            optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE))
#   )
# 
#   save(glmm_E1_rt_max, file = file_E1_rt_max)
# } else {
#   load(file_E1_rt_max)
# }
# 
# print(summary(glmm_E1_rt_max), corr = FALSE)

```


#### The zero-correlation-parameter model
```{r E1 rt zcp}
file_E1_rt_zcp <- file.path(folder_lmm, "E1_rt_lmm_zcp.RData")

# fit the zcp1 model
if (!file.exists(file_E1_rt_zcp)) {
  glmm_E1_rt_zcp <- lmer(
    log(RT) ~ Cue * Congruency * Alignment +  
      (Cue_C + Con_C + Ali_C + 
         Cue_Con + Cue_Ali + Con_Ali + 
         Cue_Con_Ali || Participant),
    data = df_lmm_E1_rt,
    control = lmerControl(optimizer = "optimx", # calc.derivs = FALSE,
                          optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE))
  )
  # save(glmm_E1_rt_zcp, file = file_E1_rt_zcp)
} else {
  load(file_E1_rt_zcp)
}

print(summary(glmm_E1_rt_zcp), corr = FALSE)
```

#### The reduced model
```{r PCA analysis for rt zcp lmm E1}
summary(rePCA(glmm_E1_rt_zcp))
```

`Con_Ali` was removed from extended model (`glmm_E1_rt_zcp`) due to that the variance it explained was smaller than 0.1%, making `glmm_E1_rt_rdc`.

```{r E1 rt rdc}
file_E1_rt_rdc <- file.path(folder_lmm, "E1_rt_lmm_rdc.RData")

# fit the rdc1 model
if (!file.exists(file_E1_rt_rdc)) {
  glmm_E1_rt_rdc <- lmer(
    log(RT) ~ Cue * Congruency * Alignment +  
      (Cue_C + Con_C + Ali_C + 
         Cue_Con + Cue_Ali + # Con_Ali + 
         Cue_Con_Ali || Participant),
    data = df_lmm_E1_rt,
    control = lmerControl(optimizer = "optimx", # calc.derivs = FALSE,
                          optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE))
  )
  # save(glmm_E1_rt_rdc, file = file_E1_rt_rdc)
} else {
  load(file_E1_rt_rdc)
}

print(summary(glmm_E1_rt_rdc), corr = FALSE)
```

#### The extended model
```{r E1 rt etd}
file_E1_rt_etd <- file.path(folder_lmm, "E1_rt_lmm_etd.RData")

# fit the etd1 model
if (!file.exists(file_E1_rt_etd)) {
  glmm_E1_rt_etd <- lmer(
    log(RT) ~ Cue * Congruency * Alignment +  
      (Cue_C + Con_C + Ali_C + 
         Cue_Con + Cue_Ali + # Con_Ali + 
         Cue_Con_Ali | Participant),
    data = df_lmm_E1_rt,
    control = lmerControl(optimizer = "optimx", # calc.derivs = FALSE,
                          optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE))
  )
  # save(glmm_E1_rt_etd, file = file_E1_rt_etd)
} else {
  load(file_E1_rt_etd)
}

print(summary(glmm_E1_rt_etd), corr = FALSE)
```

```{r PCA analysis for E1 rt etd lmm}
summary(rePCA(glmm_E1_rt_etd))
```

`Con_C`, `Ali_C`, and `Cue_Con` were removed from extended model.

```{r E1 rt etd1}
file_E1_rt_etd1 <- file.path(folder_lmm, "E1_rt_lmm_etd1.RData")

# fit the etd1 model
if (!file.exists(file_E1_rt_etd1)) {
  glmm_E1_rt_etd1 <- lmer(
    log(RT) ~ Cue * Congruency * Alignment +  
      (Cue_C + # Con_C + Ali_C + 
         Cue_Ali + # Con_Ali + Cue_Con + 
         Cue_Con_Ali | Participant),
    data = df_lmm_E1_rt,
    control = lmerControl(optimizer = "optimx", # calc.derivs = FALSE,
                          optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE))
  )
  # save(glmm_E1_rt_etd1, file = file_E1_rt_etd1)
} else {
  load(file_E1_rt_etd1)
}

print(summary(glmm_E1_rt_etd1), corr = FALSE)
```

#### The optimal model
```{r E1 comapre rt etd and rdc}
# compare the extended and reduced model
anova(glmm_E1_rt_etd1, glmm_E1_rt_rdc, refit = FALSE)
```

According to BIC, the reduced model (`glmm_E1_rt_rdc`) explained the data better than the extended model (`glmm_E1_rt_etd1`) and, therefore, the reduced model is used as the optimal model.

```{r E1 the optimal model rt}
glmm_E1_rt_opt <- glmm_E1_rt_rdc

print(summary(glmm_E1_rt_opt), corr = FALSE)
```

### Estimated marginal means
#### Estimated marginal means for RT
```{r E1 emm rt}
file_E1_rt_emm <- file.path(folder_lmm, "E1_rt_emm.RData") 
if (!file.exists(file_E1_rt_emm)) {
  emm_E1_rt <- emmeans(glmm_E1_rt_opt, ~ Cue + Congruency + Alignment)
} else {
  load(file_E1_rt_emm)
}

# emmip(regrid(emm_E1_rt), Congruency ~ Alignment | Cue, CIs = TRUE)

summary(emm_E1_rt, type = "response") # equivalent to regrid(emm_rt)
```


```{r plot for publication E1 rt slides, fig.width=3, fig.asp=.6}
plot_E1_cf_rt <- summary(emm_E1_rt, type = "response") %>% 
  as_tibble() %>% 
  ggplot(aes(y = response, x = Alignment, color = Congruency, group = Congruency)) +
  geom_point(position = position_dodge(width = 0.1), size = 2) +
  geom_line(aes(linetype = Congruency), position = position_dodge(width = 0.1),
            size = 0.8) +
  scale_linetype_manual(values=c("solid", "dashed"))+
  geom_errorbar(aes(ymin = asymp.LCL, ymax = asymp.UCL), size=1.5, width=0, 
                alpha = .6, position = position_dodge(width = 0.1),
                show.legend = F) + 
  facet_grid(. ~Cue, switch = "both") +
  coord_cartesian(ylim = ylimit_cf_rt) +  # set the limit for y axis c(0, 1100)
  labs(x = "Cues", y = "Correct response times (ms)", fill = "Congruency") +  # set the names for main, x and y axises
  geom_text(label = c("", "", "++", "+", "", "", "", ""), color = "blue", size = 6, nudge_y = 50, nudge_x = 0.5) + # add starts to the significant columns
  theme_bw() +
  theme(
    text = element_text(size = 10),
    axis.title = element_text(size = 16), 
    axis.text = element_text(size = 14), # the size of the texts in plot
    # axis.text.x = element_text(angle = 45, vjust = 0.5),
    legend.title=element_text(size=15),
    legend.text=element_text(size=14),
    legend.position = "right",
    legend.key.width = unit(1.2, "cm"),
    plot.title = element_text(lineheight=.8, face="bold", size = 17),
    panel.border = element_blank(),
    panel.grid.minor = element_blank(),
    panel.grid.major = element_blank(),
    axis.line.x = element_line(colour = 'black', size=0.5, linetype='solid'),
    axis.line.y = element_line(colour = 'black', size=0.5, linetype='solid'),
    # remove the facet background color
    strip.text = element_text(face="bold", size=14, lineheight=5.0),
    strip.background = element_rect(fill="white", colour="white", size=1),
    strip.placement = "outside"
  ) 

# ggsave(filename = "E1_cf_rt.pdf", plot_E1_cf_rt, width = 8, height = 4.8)

plot_E1_cf_rt
```

#### Composite effects
Composite face effects for top and bottom parts:
```{r}
emm_rt_cf <- contrast(regrid(emm_E1_rt), interaction = "pairwise", by = "Cue", infer = TRUE)
emm_rt_cf[1:2]
```

#### Facilitation and interference
```{r}
emm_E1_rt_fi <- contrast(regrid(emm_E1_rt), "pairwise", by = c("Cue", "Congruency"), infer=TRUE, adjust = "Tukey")

# emmip(emm_E1_rt_fi[1:4], ~ Cue | Congruency, CIs = TRUE, adjust = "Tukey")
emm_E1_rt_fi[1:4]
```

```{r fi E1 rt, fig.width=6, fig.asp=.65}
plot_E1_cffi_rt <- emm_E1_rt_fi[1:4] %>% 
  as_tibble() %>% 
  ggplot(aes(y = estimate, x = Cue, color = Congruency)) +
  geom_point(size = 2) +
  geom_errorbar(aes(ymin = asymp.LCL, ymax = asymp.UCL), size=1.5, width=0, 
                alpha = .6) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  facet_grid(. ~ Congruency, switch = "both") +
  coord_cartesian(ylim = ylimit_cf_fi_rt) +  # set the limit for y axis c(0, 1100)
  labs(x = "Congruency", y = expression(RT~"(aligned-misaligned)")) +  # set the names for main, x and y axises
  theme_bw() +
  theme(
    text = element_text(size = 10),
    axis.title = element_text(size = 16), 
    axis.text = element_text(size = 14), # the size of the texts in plot
    # axis.text.x = element_text(angle = 45, vjust = 0.5),
    legend.title=element_text(size=15),
    legend.text=element_text(size=14),
    legend.position = "none",
    legend.key.width = unit(1.2, "cm"),
    plot.title = element_text(lineheight=.8, face="bold", size = 17),
    panel.border = element_blank(),
    panel.grid.minor = element_blank(),
    panel.grid.major = element_blank(),
    axis.line.x = element_line(colour = 'black', size=0.5, linetype='solid'),
    axis.line.y = element_line(colour = 'black', size=0.5, linetype='solid'),
    # remove the facet background color
    strip.text = element_text(face="bold", size=14, lineheight=5.0),
    strip.background = element_rect(fill="white", colour="white", size=1),
    strip.placement = "outside"
  ) +
  NULL

# ggsave(filename = "E1_fi_rt.pdf", plot_E1_cffi_rt, width = 7, height = 4.55)

plot_E1_cffi_rt
```

# Experiment 2
```{r only keep E2}
df_lmm_E2 <- df_lmm %>% 
  filter(Experiment != "109_cue") %>% 
  droplevels() 

contrasts(df_lmm_E2$Probability) <- MASS::contr.sdif(2)

df_lmm_E2 <- df_lmm_E2 %>% 
  mutate(Pro_C = if_else(Probability == 0.25, -0.5, 0.5),
         Cue_Pro = Cue_C * Pro_C,
         Con_Pro = Con_C * Pro_C,
         Ali_Pro = Ali_C * Pro_C,
         Sam_Pro = Sam_C * Pro_C,
         Cue_Con_Pro = Cue_Con * Pro_C,
         Cue_Ali_Pro = Cue_Ali * Pro_C,
         Cue_Sam_Pro = Cue_Sam * Pro_C,
         Con_Ali_Pro = Con_Ali * Pro_C,
         Con_Sam_Pro = Con_Sam * Pro_C,
         Ali_Sam_Pro = Ali_Sam * Pro_C,
         Cue_Con_Ali_Pro = Cue_Con_Ali * Pro_C,
         Cue_Con_Sam_Pro = Cue_Con_Sam * Pro_C,
         Cue_Ali_Sam_Pro = Cue_Ali_Sam * Pro_C,
         Con_Ali_Sam_Pro = Con_Ali_Sam * Pro_C,
         Cue_Con_Ali_Sam_Pro = Cue_Con_Ali_Sam * Pro_C
  )

# save(df_lmm_E2, file = file.path("data", "df_lmm_E2.RData"))
```
## Response (d')
### Fitting the generalized mixed models
#### The maximal model
```{r E2 resp max d E2}

# file_E2_resp_max <- file.path(folder_lmm, "E2_Resp_lmm_max.RData")
# 
# # fit the max model
# if (!file.exists(file_E2_resp_max)) {
#   glmm_E2_resp_max <- glmer(
#     Resp ~ Cue * Congruency * Alignment * SameDifferent * Probability + 
#       (Cue * Congruency * Alignment * SameDifferent * Probability | Participant), # Con_Ali_Sam
#     family = binomial(link = "probit"),
#     data = df_lmm_E2,
#     control = glmerControl(optimizer = "optimx", # calc.derivs = FALSE,
#                            optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE))
#   )
# 
#   save(glmm_E2_resp_max, file = file_E2_resp_max)
# } else {
#   load(file_E2_resp_max)
# }
# 
# print(summary(glmm_E2_resp_max), corr = FALSE)

```

#### The zero-correlation-parameter model
```{r resp zcp E2}
file_E2_resp_zcp <- file.path(folder_lmm, "E2_Resp_lmm_zcp.RData")

# fit the zcp model
if (!file.exists(file_E2_resp_zcp)) {
  glmm_E2_resp_zcp <- glmer(
    Resp ~ Cue * Congruency * Alignment * SameDifferent * Probability + 
      (Cue_C + Con_C + Ali_C + Sam_C + 
         Cue_Con + Cue_Ali + Cue_Sam + Con_Ali + Con_Sam + Ali_Sam + 
         Cue_Con_Ali + Cue_Con_Sam + Cue_Ali_Sam + Con_Ali_Sam + 
         Cue_Con_Ali_Sam +
         Pro_C + 
         Cue_Pro + Con_Pro + Ali_Pro + Sam_Pro +
         Cue_Con_Pro + Cue_Ali_Pro + Cue_Sam_Pro + Con_Ali_Pro + Con_Sam_Pro + Ali_Sam_Pro + 
         Cue_Con_Ali_Pro + Cue_Con_Sam_Pro + Cue_Ali_Sam_Pro + Con_Ali_Sam_Pro + 
         Cue_Con_Ali_Sam_Pro || Participant),
    family = binomial(link = "probit"),
    data = df_lmm_E2,
    control = glmerControl(optimizer = "optimx", # calc.derivs = FALSE,
                           optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE))
  )
  
  # save(glmm_E2_resp_zcp, file = file_E2_resp_zcp)
} else {
  load(file_E2_resp_zcp)
}

print(summary(glmm_E2_resp_zcp), corr = FALSE)
```

#### The reduced model
```{r PCA analysis for resp zcp lmm E2}
summary(rePCA(glmm_E2_resp_zcp))
```

`Con_Ali`, `Ali_Sam`, `Cue_Con_Ali`, `Ali_Sam_Pro`, `Con_Ali_Sam_Pro`, `Cue_Con_Pro`, `Cue_Con_Ali_Pro`, `Cue_Ali_Sam`, `Con_Ali_Pro`, `Cue_Con`, `Con_C`, `Con_Pro`, and `Ali_Pro` were removed from extended model (`glmm_E2_resp_zcp`) due to that the variances they explained were smaller than 0.1%, making `glmm_E2_resp_rdc`.

```{r resp rdc E2}
file_E2_resp_rdc <- file.path(folder_lmm, "E2_Resp_lmm_rdc.RData")

# fit the rdc model
if (!file.exists(file_E2_resp_rdc)) {
  glmm_E2_resp_rdc <- glmer(
    Resp ~ Cue * Congruency * Alignment * SameDifferent * Probability + 
      (Cue_C + Ali_C + Sam_C + # Con_C + 
         Cue_Ali + Cue_Sam + Con_Sam +  # Con_Ali + Ali_Sam + Cue_Con + 
         Cue_Con_Sam + Con_Ali_Sam +  # Cue_Con_Ali + Cue_Ali_Sam + 
         Cue_Con_Ali_Sam +
         Pro_C + 
         Cue_Pro + Sam_Pro + # Con_Pro + Ali_Pro + 
         Cue_Ali_Pro + Cue_Sam_Pro + Con_Sam_Pro + # Ali_Sam_Pro + Cue_Con_Pro + Con_Ali_Pro + 
         Cue_Con_Sam_Pro + Cue_Ali_Sam_Pro + # Con_Ali_Sam_Pro + Cue_Con_Ali_Pro + 
         Cue_Con_Ali_Sam_Pro || Participant),
    family = binomial(link = "probit"),
    data = df_lmm_E2,
    control = glmerControl(optimizer = "optimx", # calc.derivs = FALSE,
                           optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE))
  )
  # save(glmm_E2_resp_rdc, file = file_E2_resp_rdc)
} else {
  load(file_E2_resp_rdc)
}

print(summary(glmm_E2_resp_rdc), corr = FALSE)
```

```{r resp rdc1 E2}
file_E2_resp_rdc1 <- file.path(folder_lmm, "E2_Resp_lmm_rdc1.RData")

# fit the rdc1 model
if (!file.exists(file_E2_resp_rdc1)) {
  ss <- getME(glmm_E2_resp_rdc, c("theta","fixef"))
  glmm_E2_resp_rdc1 <- update(
    glmm_E2_resp_rdc, start=ss,
    control=glmerControl(optimizer = "optimx", # calc.derivs = FALSE,
                         optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE)))
  # save(glmm_E2_resp_rdc1, file = file_E2_resp_rdc1)
} else {
  load(file_E2_resp_rdc1)
}

print(summary(glmm_E2_resp_rdc1), corr = FALSE)
```

`Ali_C` was further removed.

```{r resp rdc2 E2}
file_E2_resp_rdc2 <- file.path(folder_lmm, "E2_Resp_lmm_rdc2.RData")

# fit the rdc2 model
if (!file.exists(file_E2_resp_rdc2)) {
  glmm_E2_resp_rdc2 <- glmer(
    Resp ~ Cue * Congruency * Alignment * SameDifferent * Probability + 
      (Cue_C + Sam_C + # Con_C + Ali_C + 
         Cue_Ali + Cue_Sam + Con_Sam +  # Con_Ali + Ali_Sam + Cue_Con + 
         Cue_Con_Sam + Con_Ali_Sam +  # Cue_Con_Ali + Cue_Ali_Sam + 
         Cue_Con_Ali_Sam +
         Pro_C + 
         Cue_Pro + Sam_Pro + # Con_Pro + Ali_Pro + 
         Cue_Ali_Pro + Cue_Sam_Pro + Con_Sam_Pro + # Ali_Sam_Pro + Cue_Con_Pro + Con_Ali_Pro + 
         Cue_Con_Sam_Pro + Cue_Ali_Sam_Pro + # Con_Ali_Sam_Pro + Cue_Con_Ali_Pro + 
         Cue_Con_Ali_Sam_Pro || Participant),
    family = binomial(link = "probit"),
    data = df_lmm_E2,
    control = glmerControl(optimizer = "optimx", # calc.derivs = FALSE,
                           optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE))
  )
  # save(glmm_E2_resp_rdc2, file = file_E2_resp_rdc2)
} else {
  load(file_E2_resp_rdc2)
}

print(summary(glmm_E2_resp_rdc2), corr = FALSE)
```

#### The extended model
```{r resp etd E2}
file_E2_resp_etd <- file.path(folder_lmm, "E2_Resp_lmm_etd.RData")

# fit the etd model
if (!file.exists(file_E2_resp_etd)) {
  glmm_E2_resp_etd <- glmer(
    Resp ~ Cue * Congruency * Alignment * SameDifferent * Probability + 
      (Cue_C + Sam_C + # Con_C + Ali_C + 
         Cue_Ali + Cue_Sam + Con_Sam +  # Con_Ali + Ali_Sam + Cue_Con + 
         Cue_Con_Sam + Con_Ali_Sam +  # Cue_Con_Ali + Cue_Ali_Sam + 
         Cue_Con_Ali_Sam +
         Pro_C + 
         Cue_Pro + Sam_Pro + # Con_Pro + Ali_Pro + 
         Cue_Ali_Pro + Cue_Sam_Pro + Con_Sam_Pro + # Ali_Sam_Pro + Cue_Con_Pro + Con_Ali_Pro + 
         Cue_Con_Sam_Pro + Cue_Ali_Sam_Pro + # Con_Ali_Sam_Pro + Cue_Con_Ali_Pro + 
         Cue_Con_Ali_Sam_Pro | Participant),
    family = binomial(link = "probit"),
    data = df_lmm_E2,
    control = glmerControl(optimizer = "optimx", # calc.derivs = FALSE,
                           optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE))
  )
  # save(glmm_E2_resp_etd, file = file_E2_resp_etd)
} else {
  load(file_E2_resp_etd)
}

print(summary(glmm_E2_resp_etd), corr = FALSE)
```

```{r}
summary(rePCA(glmm_E2_resp_etd))
```

`Sam_Pro`, `Cue_Ali`, `Pro_C`, `Intercept`, `Cue_Ali_Pro`, `Con_Ali_Sam`, `Cue_C`, `Cue_Con_Ali_Sam`, `Con_Sam_Pro`, and `Sam_C` were removed from extended model (`glmm_E2_resp_etd`) due to that the variances they explained were smaller than 1%, making `glmm_E2_resp_etd1`.

```{r resp etd1 E2}
file_E2_resp_etd1 <- file.path(folder_lmm, "E2_Resp_lmm_etd1.RData")

# fit the etd1 model
if (!file.exists(file_E2_resp_etd1)) {
  glmm_E2_resp_etd1 <- glmer(
    Resp ~ Cue * Congruency * Alignment * SameDifferent * Probability + 
      (0 + # Con_C + Ali_C + Cue_C + Sam_C + 
         Cue_Sam + Con_Sam +  # Con_Ali + Ali_Sam + Cue_Con + Cue_Ali + 
         Cue_Con_Sam + # Cue_Con_Ali + Cue_Ali_Sam + Con_Ali_Sam +  
         # Cue_Con_Ali_Sam +
         # Pro_C + 
         Cue_Pro + # Con_Pro + Ali_Pro + Sam_Pro + 
         Cue_Sam_Pro + # Ali_Sam_Pro + Cue_Con_Pro + Con_Ali_Pro + Cue_Ali_Pro + Con_Sam_Pro + 
         Cue_Con_Sam_Pro + Cue_Ali_Sam_Pro + # Con_Ali_Sam_Pro + Cue_Con_Ali_Pro + 
         Cue_Con_Ali_Sam_Pro | Participant),
    family = binomial(link = "probit"),
    data = df_lmm_E2,
    control = glmerControl(optimizer = "optimx", # calc.derivs = FALSE,
                           optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE))
  )
  # save(glmm_E2_resp_etd1, file = file_E2_resp_etd1)
} else {
  load(file_E2_resp_etd1)
}

print(summary(glmm_E2_resp_etd1), corr = FALSE)
```

```{r}
summary(rePCA(glmm_E2_resp_etd1))
```

`Cue_Ali_Sam_Pro`, and `Con_Sam` were removed from extended model (`glmm_E2_resp_etd1`) due to that the variances they explained were smaller than 1%, making `glmm_E2_resp_etd2`.

```{r resp etd2 E2}
file_E2_resp_etd2 <- file.path(folder_lmm, "E2_Resp_lmm_etd2.RData")

# fit the etd2 model
if (!file.exists(file_E2_resp_etd2)) {
  glmm_E2_resp_etd2 <- glmer(
    Resp ~ Cue * Congruency * Alignment * SameDifferent * Probability + 
      (0 + # Con_C + Ali_C + Cue_C + Sam_C + 
         Cue_Sam +  # Con_Ali + Ali_Sam + Cue_Con + Cue_Ali + Con_Sam + 
         Cue_Con_Sam + # Cue_Con_Ali + Cue_Ali_Sam + Con_Ali_Sam +  
         # Cue_Con_Ali_Sam +
         # Pro_C + 
         Cue_Pro + # Con_Pro + Ali_Pro + Sam_Pro + 
         Cue_Sam_Pro + # Ali_Sam_Pro + Cue_Con_Pro + Con_Ali_Pro + Cue_Ali_Pro + Con_Sam_Pro + 
         Cue_Con_Sam_Pro + # Con_Ali_Sam_Pro + Cue_Con_Ali_Pro + Cue_Ali_Sam_Pro + 
         Cue_Con_Ali_Sam_Pro | Participant),
    family = binomial(link = "probit"),
    data = df_lmm_E2,
    control = glmerControl(optimizer = "optimx", # calc.derivs = FALSE,
                           optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE))
  )
  # save(glmm_E2_resp_etd2, file = file_E2_resp_etd2)
} else {
  load(file_E2_resp_etd2)
}

print(summary(glmm_E2_resp_etd2), corr = FALSE)
```

```{r resp etd3 E2}
file_E2_resp_etd3 <- file.path(folder_lmm, "E2_Resp_lmm_etd3.RData")

# fit the etd3 model
if (!file.exists(file_E2_resp_etd3)) {
  
  ss <- getME(glmm_E2_resp_etd2, c("theta","fixef"))
  glmm_E2_resp_etd3 <- update(
    glmm_E2_resp_etd2, start=ss,
    control=glmerControl(optimizer = "optimx", # calc.derivs = FALSE,
                         optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE)))
  # save(glmm_E2_resp_etd3, file = file_E2_resp_etd3)
} else {
  load(file_E2_resp_etd3)
}

print(summary(glmm_E2_resp_etd3), corr = FALSE)
```

```{r}
summary(rePCA(glmm_E2_resp_etd3))
```

`Cue_Con_Ali_Sam_Pro` was removed from extended model (`glmm_E2_resp_etd3`) due to that the variances it explained were smaller than 1%, making `glmm_E2_resp_etd4`.

```{r resp etd4 E2}
file_E2_resp_etd4 <- file.path(folder_lmm, "E2_Resp_lmm_etd4.RData")

# fit the etd4 model
if (!file.exists(file_E2_resp_etd4)) {
  glmm_E2_resp_etd4 <- glmer(
    Resp ~ Cue * Congruency * Alignment * SameDifferent * Probability + 
      (0 + # Con_C + Ali_C + Cue_C + Sam_C + 
         Cue_Sam +  # Con_Ali + Ali_Sam + Cue_Con + Cue_Ali + Con_Sam + 
         Cue_Con_Sam + # Cue_Con_Ali + Cue_Ali_Sam + Con_Ali_Sam +  
         # Cue_Con_Ali_Sam +
         # Pro_C + 
         Cue_Pro + # Con_Pro + Ali_Pro + Sam_Pro + 
         Cue_Sam_Pro + # Ali_Sam_Pro + Cue_Con_Pro + Con_Ali_Pro + Cue_Ali_Pro + Con_Sam_Pro + 
         Cue_Con_Sam_Pro # Con_Ali_Sam_Pro + Cue_Con_Ali_Pro + Cue_Ali_Sam_Pro + + Cue_Con_Ali_Sam_Pro
       | Participant),
    family = binomial(link = "probit"),
    data = df_lmm_E2,
    control = glmerControl(optimizer = "optimx", # calc.derivs = FALSE,
                           optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE))
  )
  # save(glmm_E2_resp_etd4, file = file_E2_resp_etd4)
} else {
  load(file_E2_resp_etd4)
}

print(summary(glmm_E2_resp_etd4), corr = FALSE)
```

```{r resp etd5 E2}
file_E2_resp_etd5 <- file.path(folder_lmm, "E2_Resp_lmm_etd5.RData")

# fit the etd5 model
if (!file.exists(file_E2_resp_etd5)) {
  
  ss <- getME(glmm_E2_resp_etd4, c("theta","fixef"))
  glmm_E2_resp_etd5 <- update(
    glmm_E2_resp_etd4, start=ss,
    control=glmerControl(optimizer = "optimx", # calc.derivs = FALSE,
                         optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE)))
  # save(glmm_E2_resp_etd5, file = file_E2_resp_etd5)
} else {
  load(file_E2_resp_etd5)
}

print(summary(glmm_E2_resp_etd5), corr = FALSE)
```

```{r}
summary(rePCA(glmm_E2_resp_etd5))
```

`Cue_Pro` was removed from extended model (`glmm_E2_resp_etd5`) due to that the variances it explained were smaller than 1%, making `glmm_E2_resp_etd6`.

```{r resp etd6 E2}
file_E2_resp_etd6 <- file.path(folder_lmm, "E2_Resp_lmm_etd6.RData")

# fit the etd6 model
if (!file.exists(file_E2_resp_etd6)) {
  glmm_E2_resp_etd6 <- glmer(
    Resp ~ Cue * Congruency * Alignment * SameDifferent * Probability + 
      (0 + # Con_C + Ali_C + Cue_C + Sam_C + 
         Cue_Sam +  # Con_Ali + Ali_Sam + Cue_Con + Cue_Ali + Con_Sam + 
         Cue_Con_Sam + # Cue_Con_Ali + Cue_Ali_Sam + Con_Ali_Sam +  
         # Cue_Con_Ali_Sam +
         # Pro_C + 
         # Con_Pro + Ali_Pro + Sam_Pro + Cue_Pro + 
         Cue_Sam_Pro + # Ali_Sam_Pro + Cue_Con_Pro + Con_Ali_Pro + Cue_Ali_Pro + Con_Sam_Pro + 
         Cue_Con_Sam_Pro # Con_Ali_Sam_Pro + Cue_Con_Ali_Pro + Cue_Ali_Sam_Pro + + Cue_Con_Ali_Sam_Pro
       | Participant),
    family = binomial(link = "probit"),
    data = df_lmm_E2,
    control = glmerControl(optimizer = "optimx", # calc.derivs = FALSE,
                           optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE))
  )
  # save(glmm_E2_resp_etd6, file = file_E2_resp_etd6)
} else {
  load(file_E2_resp_etd6)
}

print(summary(glmm_E2_resp_etd6), corr = FALSE)
```

#### The optimal model
```{r comapre etd and rdc E2 d}
# compare the extended and reduced model
anova(glmm_E2_resp_etd6, glmm_E2_resp_rdc2, refit = FALSE)
```

According to BIC, the reduced model (`glmm_E2_resp_rdc2`) explained the data better than the extended model (`glmm_resp_etd4`) and, therefore, the reduced model is used as the optimal model.

```{r the optimal model E2 d}
glmm_E2_resp_opt <- glmm_E2_resp_rdc2

print(summary(glmm_E2_resp_opt), corr = FALSE)
```

### Estimated marginal means
#### Estimated marginal means for hit and false alarm
```{r emm E2 resp}
(emm_E2_resp <- emmeans(glmm_E2_resp_opt, ~ Alignment + Congruency + Cue + SameDifferent + Probability))
```

#### Estimated marginal means for d'
```{r message=FALSE}
emm_E2_d <- contrast(emm_E2_resp, method = "pairwise", simple = "SameDifferent")
summary(emm_E2_d[1:16], infer = c(TRUE, FALSE))

# emmip(emm_E2_d, Congruency ~ Alignment | Cue + Probability, CIs = TRUE)
```

```{r plot for publication E2 d slides, fig.width=6, fig.asp=.6}
plot_E2_cf_d <- summary(emm_E2_d[1:16], infer = c(TRUE, FALSE)) %>% 
  as_tibble() %>% 
  ggplot(aes(y = estimate, x = Alignment, color = Congruency, group = Congruency)) +
  geom_point(position = position_dodge(width = 0.1), size = 2) +
  geom_line(aes(linetype = Congruency), position = position_dodge(width = 0.1),
            size = 0.8) +
  scale_linetype_manual(values=c("solid", "dashed"))+
  geom_errorbar(aes(ymin = asymp.LCL, ymax = asymp.UCL), size=1.5, width=0, 
                alpha = .6, position = position_dodge(width = 0.1),
                show.legend = F) + 
  facet_grid(Probability ~Cue, switch = "x",
             labeller = labeller(Probability = c(`0.25` = "25% cueing top", `0.75` = "75% cueing top"))) +
  coord_cartesian(ylim = ylimit_cf_d) +  # set the limit for y axis c(0, 1100)
  labs(x = "Cues", y = expression("Sensitivity"~italic("d'")), fill = "Congruency") +  # set the names for main, x and y axises
  geom_text(label = c("***", "", "", "", "*", "", "", "", "***", "", "", "", "", "", "", ""), color = "red", size = 6, nudge_y = 0.4, nudge_x = 0.5) + # add starts to the significant columns
  theme_bw() +
  theme(
    text = element_text(size = 10),
    axis.title = element_text(size = 16), 
    axis.text = element_text(size = 14), # the size of the texts in plot
    # axis.text.x = element_text(angle = 45, vjust = 0.5),
    legend.title=element_text(size=15),
    legend.text=element_text(size=14),
    legend.position = "right",
    legend.key.width = unit(1.2, "cm"),
    plot.title = element_text(lineheight=.8, face="bold", size = 17),
    panel.border = element_blank(),
    panel.grid.minor = element_blank(),
    panel.grid.major = element_blank(),
    axis.line.x = element_line(colour = 'black', size=0.5, linetype='solid'),
    axis.line.y = element_line(colour = 'black', size=0.5, linetype='solid'),
    # remove the facet background color
    strip.text = element_text(face="bold", size=14, lineheight=5.0),
    strip.background = element_rect(fill="white", colour="white", size=1),
    strip.placement = "outside"
  ) 

# ggsave(filename = "E2_cf_d.pdf", plot_E2_cf_d, width = 8, height = 4.8)

plot_E2_cf_d
```


#### Composite effects
Composite face effects for top and bottom parts:
```{r message=FALSE}
emm_E2_d_cf <- contrast(emm_E2_resp, interaction = "pairwise", by = c("Cue", "Probability"))
summary(emm_E2_d_cf[1:4], infer = TRUE)
```

#### Facilitation and interference
```{r message=FALSE}
# Sensitivity d'
emm_E2_d_fi <- contrast(emm_E2_resp, interaction = "pairwise", by = c("Cue", "Congruency", "Probability"), adjust = "Tukey")
summary(emm_E2_d_fi[1:8], infer=TRUE)

# emmip(emm_E2_d_fi[1:8], ~ Probability | Cue + Congruency, CIs = TRUE, adjust = "Tukey")
```

```{r fi E2 d, fig.width=6, fig.asp=.65}
plot_E2_cffi_d <- summary(emm_E2_d_fi[1:8], infer=TRUE) %>% 
  as_tibble() %>% 
  ggplot(aes(y = estimate, x = Cue, color = Congruency)) +
  geom_point(size = 2) +
  geom_errorbar(aes(ymin = asymp.LCL, ymax = asymp.UCL), size=1.5, width=0, 
                alpha = .6) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  facet_grid(Probability ~ Congruency, switch = "x",
             labeller = labeller(Probability = c(`0.25` = "25% cueing top", `0.75` = "75% cueing top"))) +
  coord_cartesian(ylim = ylimit_cf_fi_d) +  # set the limit for y axis c(0, 1100)
  labs(x = "Congruency", y = expression(italic("d'")~"(aligned-misaligned)")) +  # set the names for main, x and y axises
  theme_bw() +
  theme(
    text = element_text(size = 10),
    axis.title = element_text(size = 16), 
    axis.text = element_text(size = 14), # the size of the texts in plot
    # axis.text.x = element_text(angle = 45, vjust = 0.5),
    legend.title=element_text(size=15),
    legend.text=element_text(size=14),
    legend.position = "none",
    legend.key.width = unit(1.2, "cm"),
    plot.title = element_text(lineheight=.8, face="bold", size = 17),
    panel.border = element_blank(),
    panel.grid.minor = element_blank(),
    panel.grid.major = element_blank(),
    axis.line.x = element_line(colour = 'black', size=0.5, linetype='solid'),
    axis.line.y = element_line(colour = 'black', size=0.5, linetype='solid'),
    # remove the facet background color
    strip.text = element_text(face="bold", size=14, lineheight=5.0),
    strip.background = element_rect(fill="white", colour="white", size=1),
    strip.placement = "outside"
  ) +
  NULL

# ggsave(filename = "E2_fi_d.pdf", plot_E2_cffi_d, width = 7, height = 4.55)

plot_E2_cffi_d
```


```{r message=FALSE}
# Sensitivity d'
test2 <- contrast(regrid(emm_E2_resp), method = "pairwise", simple = "Alignment", adjust = "Tukey")
summary(test2[1:16], infer=TRUE)
```

## Response times
```{r only keep correct trials (but with both same and different trials) E2}
df_lmm_E2_rt <- df_lmm_E2 %>% 
  filter(isCorrect == 1)

# save(df_lmm_E2_rt, file = file.path("data", "df_lmm_E2_rt.RData"))
```

### Fitting the generalized mixed models
with log-transformation.
#### The maximal model
```{r E2 rt max}
# file_E2_rt_max <- file.path(folder_lmm, "E2_rt_lmm_max.RData")
# 
# # fit the max model
# if (!file.exists(file_E2_rt_max)) {
#   glmm_E2_rt_max <- glmer(
#     log(RT) ~ Cue * Congruency * Alignment * Probability + 
#       (Cue * Congruency * Alignment * Probability | Participant), 
#     family = lognormal(),
#     data = df_lmm_rt,
#     control = glmerControl(optimizer = "optimx", # calc.derivs = FALSE,
#                            optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE))
#   )
# 
#   save(glmm_E2_rt_max, file = file_E2_rt_max)
# } else {
#   load(file_E2_rt_max)
# }
# 
# print(summary(glmm_E2_rt_max), corr = FALSE)

```


#### The zero-correlation-parameter model
```{r E2 rt zcp}
file_E2_rt_zcp <- file.path(folder_lmm, "E2_rt_lmm_zcp.RData")

# fit the zcp1 model
if (!file.exists(file_E2_rt_zcp)) {
  glmm_E2_rt_zcp <- lmer(
    log(RT) ~ Cue * Congruency * Alignment * Probability +  
      (Cue_C + Con_C + Ali_C + 
         Cue_Con + Cue_Ali + Con_Ali + 
         Cue_Con_Ali +
         Pro_C +
         Cue_Pro + Con_Pro + Ali_Pro + 
         Cue_Con_Pro + Cue_Ali_Pro + Con_Ali_Pro + 
         Cue_Con_Ali_Pro || Participant),
    data = df_lmm_E2_rt,
    control = lmerControl(optimizer = "optimx", # calc.derivs = FALSE,
                          optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE))
  )
  # save(glmm_E2_rt_zcp, file = file_E2_rt_zcp)
} else {
  load(file_E2_rt_zcp)
}

print(summary(glmm_E2_rt_zcp), corr = FALSE)
```

#### The reduced model
```{r PCA analysis for rt zcp lmm E2}
summary(rePCA(glmm_E2_rt_zcp))
```

`Cue_Ali`, `Ali_Pro`, `Con_Ali_Pro`, `Con_Pro`, `Cue_Con_Pro`, and `Cue_Con_Ali_Pro` were removed from extended model (`glmm_E2_rt_zcp`) due to that the variance it explained was smaller than 0.1%, making `glmm_E2_rt_rdc`.

```{r E2 rt rdc}
file_E2_rt_rdc <- file.path(folder_lmm, "E2_rt_lmm_rdc.RData")

# fit the rdc1 model
if (!file.exists(file_E2_rt_rdc)) {
  glmm_E2_rt_rdc <- lmer(
    log(RT) ~ Cue * Congruency * Alignment * Probability +  
      (Cue_C + Con_C + Ali_C + 
         Cue_Con + Con_Ali + # Cue_Ali + 
         Cue_Con_Ali +
         Pro_C +
         Cue_Pro +  # Ali_Pro + Con_Pro +
         Cue_Ali_Pro  # Con_Ali_Pro + Cue_Con_Pro + 
          || Participant), # Cue_Con_Ali_Pro
    data = df_lmm_E2_rt,
    control = lmerControl(optimizer = "optimx", # calc.derivs = FALSE,
                          optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE))
  )
  # save(glmm_E2_rt_rdc, file = file_E2_rt_rdc)
} else {
  load(file_E2_rt_rdc)
}

print(summary(glmm_E2_rt_rdc), corr = FALSE)
```

#### The extended model
```{r E2 rt etd}
file_E2_rt_etd <- file.path(folder_lmm, "E2_rt_lmm_etd.RData")

# fit the etd model
if (!file.exists(file_E2_rt_etd)) {
  glmm_E2_rt_etd <- lmer(
    log(RT) ~ Cue * Congruency * Alignment * Probability +  
      (Cue_C + Con_C + Ali_C + 
         Cue_Con + Con_Ali + # Cue_Ali + 
         Cue_Con_Ali +
         Pro_C +
         Cue_Pro +  # Ali_Pro + Con_Pro +
         Cue_Ali_Pro  # Con_Ali_Pro + Cue_Con_Pro + 
          | Participant), # Cue_Con_Ali_Pro
    data = df_lmm_E2_rt,
    control = lmerControl(optimizer = "optimx", # calc.derivs = FALSE,
                          optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE))
  )
  # save(glmm_E2_rt_etd, file = file_E2_rt_etd)
} else {
  load(file_E2_rt_etd)
}

print(summary(glmm_E2_rt_etd), corr = FALSE)
```

```{r PCA analysis for E2 rt etd lmm}
summary(rePCA(glmm_E2_rt_etd))
```
`Con_C`, `Ali_C`, `Cue_C`, and `Cue_Ali_Pro` were removed from extended model.

```{r E2 rt etd1}
file_E2_rt_etd1 <- file.path(folder_lmm, "E2_rt_lmm_etd1.RData")

# fit the etd1 model
if (!file.exists(file_E2_rt_etd1)) {
  glmm_E2_rt_etd1 <- lmer(
    log(RT) ~ Cue * Congruency * Alignment * Probability +  
      ( # Cue_C + Con_C + Ali_C + 
         Cue_Con + Con_Ali + # Cue_Ali + 
         Cue_Con_Ali +
         Pro_C +
         Cue_Pro  # Ali_Pro + Con_Pro +
           # Con_Ali_Pro + Cue_Con_Pro + Cue_Ali_Pro
          | Participant), # Cue_Con_Ali_Pro
    data = df_lmm_E2_rt,
    control = lmerControl(optimizer = "optimx", # calc.derivs = FALSE,
                          optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE))
  )
  # save(glmm_E2_rt_etd1, file = file_E2_rt_etd1)
} else {
  load(file_E2_rt_etd1)
}

print(summary(glmm_E2_rt_etd1), corr = FALSE)
```

```{r PCA analysis for E2 rt etd1 lmm}
summary(rePCA(glmm_E2_rt_etd1))
```
`Cue_Con`, `Con_Ali`, and `Cue_Con_Ali` were removed from extended model.

```{r E2 rt etd2}
file_E2_rt_etd2 <- file.path(folder_lmm, "E2_rt_lmm_etd2.RData")

# fit the etd2 model
if (!file.exists(file_E2_rt_etd2)) {
  glmm_E2_rt_etd2 <- lmer(
    log(RT) ~ Cue * Congruency * Alignment * Probability +  
      ( # Cue_C + Con_C + Ali_C + 
         # Cue_Ali + Con_Ali + Cue_Con + 
         # Cue_Con_Ali +
         Pro_C +
         Cue_Pro  # Ali_Pro + Con_Pro +
           # Con_Ali_Pro + Cue_Con_Pro + Cue_Ali_Pro
          | Participant), # Cue_Con_Ali_Pro
    data = df_lmm_E2_rt,
    control = lmerControl(optimizer = "optimx", # calc.derivs = FALSE,
                          optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE))
  )
  # save(glmm_E2_rt_etd2, file = file_E2_rt_etd2)
} else {
  load(file_E2_rt_etd2)
}

print(summary(glmm_E2_rt_etd2), corr = FALSE)
```

#### The optimal model
```{r E2 comapre rt etd and rdc}
# compare the extended and reduced model
anova(glmm_E2_rt_etd2, glmm_E2_rt_rdc, refit = FALSE)
```

According to BIC, the reduced model (`glmm_E2_rt_rdc`) explained the data better than the extended model (`glmm_E2_rt_etd1`) and, therefore, the reduced model is used as the optimal model.

```{r E2 the optimal model rt}
glmm_E2_rt_opt <- glmm_E2_rt_rdc

print(summary(glmm_E2_rt_opt), corr = FALSE)
```

### Estimated marginal means
#### Estimated marginal means for RT
```{r E2 emm rt}
file_E2_rt_emm <- file.path(folder_lmm, "E2_rt_emm.RData") 
if (!file.exists(file_E2_rt_emm)) {
  emm_E2_rt <- emmeans(glmm_E2_rt_opt, ~ Cue + Congruency + Alignment + Probability)
} else {
  load(file_E2_rt_emm)
}

summary(emm_E2_rt, type = "response") # equivalent to regrid(emm_rt)

# emmip(regrid(emm_E2_rt), Congruency ~ Alignment | Cue + Probability, CIs = TRUE)
```


```{r plot for publication E2 rt slides, fig.width=6, fig.asp=.6}
plot_E2_cf_rt <- summary(emm_E2_rt, type = "response") %>% 
  as_tibble() %>% 
  ggplot(aes(y = response, x = Alignment, color = Congruency, group = Congruency)) +
  geom_point(position = position_dodge(width = 0.1), size = 2) +
  geom_line(aes(linetype = Congruency), position = position_dodge(width = 0.1),
            size = 0.8) +
  scale_linetype_manual(values=c("solid", "dashed"))+
  geom_errorbar(aes(ymin = asymp.LCL, ymax = asymp.UCL), size=1.5, width=0, 
                alpha = .6, position = position_dodge(width = 0.1),
                show.legend = F) + 
  facet_grid(Probability ~Cue, switch = "x",
             labeller = labeller(Probability = c(`0.25` = "25% cueing top", `0.75` = "75% cueing top"))) +
  coord_cartesian(ylim = ylimit_cf_rt) +  # set the limit for y axis c(0, 1100)
  labs(x = "Cues", y = "Correct response times (ms)", fill = "Congruency") +  # set the names for main, x and y axises
  geom_text(label = c("", "", "**", "***", "", "", "", "", "", "", "*", "*", "", "", "", ""), color = "red", size = 6, nudge_y = 50, nudge_x = 0.5) + # add starts to the significant columns
  theme_bw() +
  theme(
    text = element_text(size = 10),
    axis.title = element_text(size = 16), 
    axis.text = element_text(size = 14), # the size of the texts in plot
    # axis.text.x = element_text(angle = 45, vjust = 0.5),
    legend.title=element_text(size=15),
    legend.text=element_text(size=14),
    legend.position = "right",
    legend.key.width = unit(1.2, "cm"),
    plot.title = element_text(lineheight=.8, face="bold", size = 17),
    panel.border = element_blank(),
    panel.grid.minor = element_blank(),
    panel.grid.major = element_blank(),
    axis.line.x = element_line(colour = 'black', size=0.5, linetype='solid'),
    axis.line.y = element_line(colour = 'black', size=0.5, linetype='solid'),
    # remove the facet background color
    strip.text = element_text(face="bold", size=14, lineheight=5.0),
    strip.background = element_rect(fill="white", colour="white", size=1),
    strip.placement = "outside"
  ) 

# ggsave(filename = "E2_cf_rt.pdf", plot_E2_cf_rt, width = 8, height = 4.8)

plot_E2_cf_rt
```

#### Composite effects
Composite face effects for top and bottom parts:
```{r}
emm_rt_cf <- contrast(regrid(emm_E2_rt), interaction = "pairwise", by = c("Cue", "Probability"), infer = TRUE)
emm_rt_cf[1:4]
```

#### Facilitation and interference
```{r}
emm_E2_rt_fi <- contrast(regrid(emm_E2_rt), "pairwise", by = c("Cue", "Congruency", "Probability"), infer=TRUE, adjust = "Tukey")
emm_E2_rt_fi[1:8]
```

```{r message=FALSE}
# emmip(emm_E2_rt_fi[1:8], ~ Probability | Cue + Congruency, CIs = TRUE, adjust = "Tukey") +
#   geom_hline(yintercept = 0, linetype = "dashed")
```

```{r fi E2 rt, fig.width=6, fig.asp=.65}
plot_E2_cffi_rt <- emm_E2_rt_fi[1:8] %>% 
  as_tibble() %>% 
  ggplot(aes(y = estimate, x = Cue, color = Congruency)) +
  geom_point(size = 2) +
  geom_errorbar(aes(ymin = asymp.LCL, ymax = asymp.UCL), size=1.5, width=0, 
                alpha = .6) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  facet_grid(Probability ~ Congruency, switch = "x",
             labeller = labeller(Probability = c(`0.25` = "25% cueing top", `0.75` = "75% cueing top"))) +
  coord_cartesian(ylim = ylimit_cf_fi_rt) +  # set the limit for y axis c(0, 1100)
  labs(x = "Congruency", y = expression(RT~"(aligned-misaligned)")) +  # set the names for main, x and y axises
  theme_bw() +
  theme(
    text = element_text(size = 10),
    axis.title = element_text(size = 16), 
    axis.text = element_text(size = 14), # the size of the texts in plot
    # axis.text.x = element_text(angle = 45, vjust = 0.5),
    legend.title=element_text(size=15),
    legend.text=element_text(size=14),
    legend.position = "none",
    legend.key.width = unit(1.2, "cm"),
    plot.title = element_text(lineheight=.8, face="bold", size = 17),
    panel.border = element_blank(),
    panel.grid.minor = element_blank(),
    panel.grid.major = element_blank(),
    axis.line.x = element_line(colour = 'black', size=0.5, linetype='solid'),
    axis.line.y = element_line(colour = 'black', size=0.5, linetype='solid'),
    # remove the facet background color
    strip.text = element_text(face="bold", size=14, lineheight=5.0),
    strip.background = element_rect(fill="white", colour="white", size=1),
    strip.placement = "outside"
  ) +
  NULL

# ggsave(filename = "E2_fi_rt.pdf", plot_E2_cffi_rt, width = 7, height = 4.55)

plot_E2_cffi_rt
```


#### Comparisons between facilitation and interference

```{r}
contrast(emm_E2_rt_fi, method = list("faci-inte"=c(1, 1)), by = c("Cue", "Probability")) %>% 
  summary(infer = TRUE)
```

```{r}
emmeans(regrid(emm_E2_rt), ~ Alignment | Cue + Probability) %>% 
  contrast(interaction = "pairwise") %>% 
  summary(infer = TRUE)
```


# Experiment 1 and 2
## Responses (d')
### Fitting the generalized mixed models
#### The maximal model
```{r resp max d}

# file_resp_max <- file.path(folder_lmm, "Resp_lmm_max.RData")
# 
# # fit the max model
# if (!file.exists(file_resp_max)) {
#   glmm_resp_max <- glmer(
#     Resp ~ Cue * Congruency * Alignment * SameDifferent + Probability +
#       (Cue * Congruency * Alignment * SameDifferent | Participant), # Con_Ali_Sam
#     family = binomial(link = "probit"),
#     data = df_lmm,
#     control = glmerControl(optimizer = "optimx", # calc.derivs = FALSE,
#                            optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE))
#   )
# 
#   save(glmm_resp_max, file = file_resp_max)
# } else {
#   load(file_resp_max)
# }
# 
# print(summary(glmm_resp_max), corr = FALSE)

```

#### The zero-correlation-parameter model
```{r resp zcp}

file_resp_zcp <- file.path(folder_lmm, "Resp_lmm_zcp.RData")

# fit the zcp model
if (!file.exists(file_resp_zcp)) {
  glmm_resp_zcp <- glmer(
    Resp ~ Cue * Congruency * Alignment * SameDifferent + Probability + 
      (Cue_C + Con_C + Ali_C + Sam_C + 
         Cue_Con + Cue_Ali + Cue_Sam + Con_Ali + Con_Sam + Ali_Sam +
         Cue_Con_Ali + Cue_Con_Sam + Cue_Ali_Sam + Con_Ali_Sam + 
         Cue_Con_Ali_Sam || Participant),
    family = binomial(link = "probit"),
    data = df_lmm,
    control = glmerControl(optimizer = "optimx", # calc.derivs = FALSE,
                           optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE))
  )
  
  # save(glmm_resp_zcp, file = file_resp_zcp)
} else {
  load(file_resp_zcp)
}

print(summary(glmm_resp_zcp), corr = FALSE)

```

#### The reduced model
```{r PCA analysis for resp zcp lmm}
summary(rePCA(glmm_resp_zcp))
```

`Con_Ali`, `Ali_Sam`, `Cue_Con_Ali`, and `Cue_Ali_Sam` were removed from extended model (`glmm_resp_etd`) due to that the variances they explained were smaller than 0.1%, making `glmm_resp_rdc`.

```{r resp reduced}
file_resp_rdc <- file.path(folder_lmm, "Resp_lmm_rdc.RData")

# fit the zcp model
# three random effects were removed
if (!file.exists(file_resp_rdc)) {
  glmm_resp_rdc <- glmer(
    Resp ~ Cue * Congruency * Alignment * SameDifferent + Probability + 
      (Cue_C + Con_C + Ali_C + Sam_C + 
         Cue_Con + Cue_Ali + Cue_Sam + Con_Sam + # Con_Ali + Ali_Sam + 
         Cue_Con_Sam + Con_Ali_Sam +# Cue_Con_Ali + Cue_Ali_Sam + 
         Cue_Con_Ali_Sam || Participant),
    family = binomial(link = "probit"),
    data = df_lmm,
    control = glmerControl(optimizer = "optimx", # calc.derivs = FALSE,
                           optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE))
  )
  
  # save(glmm_resp_rdc, file = file_resp_rdc)
} else {
  load(file_resp_rdc)
}

print(summary(glmm_resp_rdc), corr = FALSE)
```

#### The extended model
```{r resp exteded model glmm_resp_rdc}
file_resp_etd <- file.path(folder_lmm, "Resp_lmm_etd.RData")

# fit the etd model
if (!file.exists(file_resp_etd)) {
  glmm_resp_etd <- glmer(
    Resp ~ Cue * Congruency * Alignment * SameDifferent + Probability + 
      (Cue_C + Con_C + Ali_C + Sam_C + 
         Cue_Con + Cue_Ali + Cue_Sam + Con_Sam + # Con_Ali + Ali_Sam + 
         Cue_Con_Sam + Con_Ali_Sam +# Cue_Con_Ali + Cue_Ali_Sam + 
         Cue_Con_Ali_Sam | Participant),
    family = binomial(link = "probit"),
    data = df_lmm,
    control = glmerControl(optimizer = "optimx", # calc.derivs = FALSE,
                           optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE))
  )
  
  # save(glmm_resp_etd, file = glmm_resp_etd)
} else {
  load(file_resp_etd)
}

print(summary(glmm_resp_etd), corr = FALSE)
```

```{r PCA analysis for resp etd lmm}
summary(rePCA(glmm_resp_etd))
```

`Con_C`, `Cue_Con`, `Ali_C`, and `Cue_Ali` was removed from extended model.

```{r resp exteded1 model}
file_resp_etd1 <- file.path(folder_lmm, "Resp_lmm_etd1.RData")

# fit the etd1 model
if (!file.exists(file_resp_etd1)) {
  glmm_resp_etd1 <- glmer(
    Resp ~ Cue * Congruency * Alignment * SameDifferent + Probability + 
      (Cue_C + Sam_C + # Con_C + Ali_C +
         Cue_Sam + Con_Sam + # Cue_Con + Con_Ali + Ali_Sam + Cue_Ali + 
         Cue_Con_Sam + Con_Ali_Sam +# Cue_Con_Ali + Cue_Ali_Sam + 
         Cue_Con_Ali_Sam | Participant),
    family = binomial(link = "probit"),
    data = df_lmm,
    control = glmerControl(optimizer = "optimx", # calc.derivs = FALSE,
                           optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE))
  )
  # save(glmm_resp_etd1, file = glmm_resp_etd1)
} else {
  load(file_resp_etd1)
}

print(summary(glmm_resp_etd1), corr = FALSE)
```

```{r PCA analysis for resp etd1 lmm}
summary(rePCA(glmm_resp_etd1))
```

`Intercept` was removed from extended1 model.

```{r resp exteded2 model}
file_resp_etd2 <- file.path(folder_lmm, "Resp_lmm_etd2.RData")

# fit the etd2 model
if (!file.exists(file_resp_etd2)) {
  glmm_resp_etd2 <- glmer(
    Resp ~ Cue * Congruency * Alignment * SameDifferent + Probability + 
      (0 + Cue_C + Sam_C + # Con_C + Ali_C +
         Cue_Sam + Con_Sam + # Cue_Con + Con_Ali + Ali_Sam + Cue_Ali + 
         Cue_Con_Sam + Con_Ali_Sam +# Cue_Con_Ali + Cue_Ali_Sam + 
         Cue_Con_Ali_Sam | Participant),
    family = binomial(link = "probit"),
    data = df_lmm,
    control = glmerControl(optimizer = "optimx", # calc.derivs = FALSE,
                           optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE))
  )
  
  # save(glmm_resp_etd2, file = glmm_resp_etd2)
} else {
  load(file_resp_etd2)
}

print(summary(glmm_resp_etd2), corr = FALSE)
```

```{r PCA analysis for resp etd2 lmm}
summary(rePCA(glmm_resp_etd2))
```

`Con_Ali_Sam` was removed from extended1 model.

```{r resp exteded3 model}
file_resp_etd3 <- file.path(folder_lmm, "Resp_lmm_etd3.RData")

# fit the etd3 model
if (!file.exists(file_resp_etd3)) {
  glmm_resp_etd3 <- glmer(
    Resp ~ Cue * Congruency * Alignment * SameDifferent + Probability + 
      (0 + Cue_C + Sam_C + # Con_C + Ali_C +
         Cue_Sam + Con_Sam + # Cue_Con + Con_Ali + Ali_Sam + Cue_Ali + 
         Cue_Con_Sam + # Cue_Con_Ali + Cue_Ali_Sam + Con_Ali_Sam +
         Cue_Con_Ali_Sam | Participant),
    family = binomial(link = "probit"),
    data = df_lmm,
    control = glmerControl(optimizer = "optimx", # calc.derivs = FALSE,
                           optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE))
  )
  # save(glmm_resp_etd3, file = glmm_resp_etd3)
} else {
  load(file_resp_etd3)
}

print(summary(glmm_resp_etd3), corr = FALSE)
```


```{r PCA analysis for resp etd3 lmm}
summary(rePCA(glmm_resp_etd3))
```

`Cue_C` was removed.

```{r resp exteded4 model}
file_resp_etd4 <- file.path(folder_lmm, "Resp_lmm_etd4.RData")

# fit the etd4 model
if (!file.exists(file_resp_etd4)) {
  glmm_resp_etd4 <- glmer(
    Resp ~ Cue * Congruency * Alignment * SameDifferent + Probability + 
      (0 + Sam_C + # Con_C + Ali_C + Cue_C + 
         Cue_Sam + Con_Sam + # Cue_Con + Con_Ali + Ali_Sam + Cue_Ali + 
         Cue_Con_Sam + # Cue_Con_Ali + Cue_Ali_Sam + Con_Ali_Sam +
         Cue_Con_Ali_Sam | Participant),
    family = binomial(link = "probit"),
    data = df_lmm,
    control = glmerControl(optimizer = "optimx", # calc.derivs = FALSE,
                           optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE))
  )
  # save(glmm_resp_etd4, file = glmm_resp_etd4)
} else {
  load(file_resp_etd4)
}

print(summary(glmm_resp_etd4), corr = FALSE)
```


```{r PCA analysis for resp etd4 lmm}
summary(rePCA(glmm_resp_etd4))
```

`Cue_Con_Ali_Sam` was removed. 

```{r resp exteded5 model}
file_resp_etd5 <- file.path(folder_lmm, "Resp_lmm_etd5.RData")

# fit the etd5 model
if (!file.exists(file_resp_etd5)) {
  glmm_resp_etd5 <- glmer(
    Resp ~ Cue * Congruency * Alignment * SameDifferent + Probability + 
      (0 + Sam_C + # Con_C + Ali_C + Cue_C + 
         Cue_Sam + Con_Sam + # Cue_Con + Con_Ali + Ali_Sam + Cue_Ali + 
         Cue_Con_Sam  # Cue_Con_Ali + Cue_Ali_Sam + Con_Ali_Sam + +
          | Participant), # Cue_Con_Ali_Sam
    family = binomial(link = "probit"),
    data = df_lmm,
    control = glmerControl(optimizer = "optimx", # calc.derivs = FALSE,
                           optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE))
  )
  # save(glmm_resp_etd5, file = glmm_resp_etd5)
} else {
  load(file_resp_etd5)
}

print(summary(glmm_resp_etd5), corr = FALSE)
```

#### The optimal model

```{r comapre etd and rdc d}
# compare the extended and reduced model
anova(glmm_resp_etd5, glmm_resp_rdc, refit = FALSE)
```

According to BIC, the reduced model (`glmm_resp_rdc`) explained the data better than the extended model (`glmm_resp_etd5`) and, therefore, the reduced model is used as the optimal model.

```{r the optimal model d}
glmm_resp_opt <- glmm_resp_rdc

print(summary(glmm_resp_opt), corr = FALSE)
```


### Estimated marginal means
#### Estimated marginal means for hit and false alarm
```{r emm}
(emm_resp <- emmeans(glmm_resp_opt, ~ Alignment + Congruency + Cue + SameDifferent))
```

#### Estimated marginal means for d'
```{r message=FALSE}
emm_d <- contrast(emm_resp, method = "pairwise", simple = "SameDifferent")
summary(emm_d[1:8], infer = c(TRUE, FALSE))
```

```{r message=FALSE}
emmip(emm_d, Congruency ~ Alignment | Cue, CIs = TRUE)
```

```{r plot for publication E12 d slides, fig.width=3, fig.asp=.6}
plot_E12_cf_d <- summary(emm_d[1:8], infer = c(TRUE, FALSE)) %>% 
  as_tibble() %>% 
  ggplot(aes(y = estimate, x = Alignment, color = Congruency, group = Congruency)) +
  geom_point(position = position_dodge(width = 0.1), size = 2) +
  geom_line(aes(linetype = Congruency), position = position_dodge(width = 0.1),
            size = 0.8) +
  scale_linetype_manual(values=c("solid", "dashed"))+
  geom_errorbar(aes(ymin = asymp.LCL, ymax = asymp.UCL), size=1.5, width=0, 
                alpha = .6, position = position_dodge(width = 0.1),
                show.legend = F) + 
  facet_grid(. ~Cue, switch = "both") +
  coord_cartesian(ylim = ylimit_cf_d) +  # set the limit for y axis c(0, 1100)
  labs(x = "Cues", y = expression("Sensitivity"~italic("d'")), fill = "Congruency") +  # set the names for main, x and y axises
  geom_text(label = c("***", "", "", "", "**", "", "", ""), color = "red", size = 6, nudge_y = 0.5, nudge_x = 0.5) + # add starts to the significant columns
  theme_bw() +
  theme(
    text = element_text(size = 10),
    axis.title = element_text(size = 16), 
    axis.text = element_text(size = 14), # the size of the texts in plot
    # axis.text.x = element_text(angle = 45, vjust = 0.5),
    legend.title=element_text(size=15),
    legend.text=element_text(size=14),
    legend.position = "right",
    legend.key.width = unit(1.2, "cm"),
    plot.title = element_text(lineheight=.8, face="bold", size = 17),
    panel.border = element_blank(),
    panel.grid.minor = element_blank(),
    panel.grid.major = element_blank(),
    axis.line.x = element_line(colour = 'black', size=0.5, linetype='solid'),
    axis.line.y = element_line(colour = 'black', size=0.5, linetype='solid'),
    # remove the facet background color
    strip.text = element_text(face="bold", size=14, lineheight=5.0),
    strip.background = element_rect(fill="white", colour="white", size=1),
    strip.placement = "outside"
  ) 

# ggsave(filename = "E12_cf_d.pdf", plot_E12_cf_d, width = 8, height = 4.8)

plot_E12_cf_d
```


#### Composite effects
Composite face effects for top and bottom parts:
```{r message=FALSE}
emm_d_cf <- contrast(emm_resp, interaction = "pairwise", by = "Cue")
summary(emm_d_cf[1:2], infer = TRUE)
```

#### Facilitation and interference
```{r message=FALSE}
# Sensitivity d'
emm_d_fi <- contrast(emm_resp, interaction = "pairwise", by = c("Cue", "Congruency"), adjust = "Tukey")
summary(emm_d_fi[1:4], infer=TRUE)
```

```{r message=FALSE}
# showing the differences between aligned and misaligned (aligned-misaligned)
emmip(emm_d_fi[1:4], ~ Cue | Congruency, CIs = TRUE, adjust = "Tukey") +
  geom_hline(yintercept = 0, linetype = "dashed")
```

```{r fi E12 d, fig.width=3, fig.asp=.65}
plot_E12_cffi_d <- summary(emm_d_fi[1:4], infer=TRUE) %>% 
  as_tibble() %>% 
  ggplot(aes(y = estimate, x = Cue, color = Congruency)) +
  geom_point(size = 2) +
  geom_errorbar(aes(ymin = asymp.LCL, ymax = asymp.UCL), size=1.5, width=0, 
                alpha = .6) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  facet_grid(. ~ Congruency, switch = "both") +
  coord_cartesian(ylim = ylimit_cf_fi_d) +  # set the limit for y axis c(0, 1100)
  labs(x = "Congruency", y = expression(italic("d'")~"(aligned-misaligned)")) +  # set the names for main, x and y axises
  theme_bw() +
  theme(
    text = element_text(size = 10),
    axis.title = element_text(size = 16), 
    axis.text = element_text(size = 14), # the size of the texts in plot
    # axis.text.x = element_text(angle = 45, vjust = 0.5),
    legend.title=element_text(size=15),
    legend.text=element_text(size=14),
    legend.position = "none",
    legend.key.width = unit(1.2, "cm"),
    plot.title = element_text(lineheight=.8, face="bold", size = 17),
    panel.border = element_blank(),
    panel.grid.minor = element_blank(),
    panel.grid.major = element_blank(),
    axis.line.x = element_line(colour = 'black', size=0.5, linetype='solid'),
    axis.line.y = element_line(colour = 'black', size=0.5, linetype='solid'),
    # remove the facet background color
    strip.text = element_text(face="bold", size=14, lineheight=5.0),
    strip.background = element_rect(fill="white", colour="white", size=1),
    strip.placement = "outside"
  ) +
  NULL

# ggsave(filename = "E12_fi_d.pdf", plot_E12_cffi_d, width = 7, height = 4.55)

plot_E12_cffi_d
```

#### Comparisons between facilitation and interference

```{r}
contrast(emm_d_fi, method = list("faci-inte"=c(1, 1)), by = "Cue") %>% 
  summary(infer = TRUE)
```

```{r}
# contrast(emm_d, method = list("faci-inte"=c(1, -1, 1, -1 )), by = "Cue") %>%
#   summary(infer = TRUE)
```


```{r}
# emmeans(glmm_resp_opt, ~ Alignment + SameDifferent | Cue ) %>%
#   contrast(interaction = "pairwise")
```

#### SCF analysis
```{r message=FALSE}
# Accuracy for same trials only
emm_resp_scf <- contrast(regrid(emm_resp), method = "pairwise", simple = "Alignment")
summary(emm_resp_scf[1:4], infer = TRUE)

```

```{r}
# Accuracy for different trials only
# emm_resp_scf[5:8]
```

```{r message=FALSE}
# false alarm
emmip(emm_resp_scf, ~ Cue | SameDifferent + Congruency, CIs = TRUE) +
  geom_hline(yintercept = 0, linetype = "dashed")
```

## Response times
```{r only keep correct trials (but with both same and different trials)}
df_lmm_rt <- df_lmm %>% 
  filter(isCorrect == 1)

# save(df_lmm_rt, file = file.path("data", "df_lmm_rt.RData"))
```

### Fitting the generalized mixed models
with log-transformation.
#### The maximal model
```{r rt max}
# file_rt_max <- file.path(folder_lmm, "rt_lmm_max.RData")
# 
# # fit the max model
# if (!file.exists(file_rt_max)) {
#   glmm_rt_max <- glmer(
#     log(RT) ~ Cue * Congruency * Alignment + Probability +
#       (Cue * Congruency * Alignment | Participant), 
#     family = lognormal(),
#     data = df_lmm_rt,
#     control = glmerControl(optimizer = "optimx", # calc.derivs = FALSE,
#                            optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE))
#   )
# 
#   save(glmm_rt_max, file = file_rt_max)
# } else {
#   load(file_rt_max)
# }
# 
# print(summary(glmm_rt_max), corr = FALSE)

```


#### The zero-correlation-parameter model
```{r rt zcp}

file_rt_zcp <- file.path(folder_lmm, "rt_lmm_zcp.RData")

# fit the zcp1 model
if (!file.exists(file_rt_zcp)) {
  glmm_rt_zcp <- lmer(
    log(RT) ~ Cue * Congruency * Alignment + Probability + 
      (Cue_C + Con_C + Ali_C + 
         Cue_Con + Cue_Ali + Con_Ali + 
         Cue_Con_Ali || Participant),
    data = df_lmm_rt,
    control = lmerControl(optimizer = "optimx", # calc.derivs = FALSE,
                          optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE))
  )
    # save(glmm_rt_zcp, file = file_rt_zcp)
} else {
    load(file_rt_zcp)
}

print(summary(glmm_rt_zcp), corr = FALSE)

```

#### The reduced model
```{r PCA analysis for rt zcp lmm}
summary(rePCA(glmm_rt_zcp))
```

`Con_Ali`, and `Cue_Ali` were removed from extended model (`glmm_rt_zcp`) due to that the variances they explained were smaller than 0.1%, making `glmm_rt_rdc`.

```{r rt reduced}
file_rt_rdc <- file.path(folder_lmm, "rt_lmm_rdc.RData")

# fit the zcp model
# three random effects were removed
if (!file.exists(file_rt_rdc)) {
  glmm_rt_rdc <- lmer(
    log(RT) ~ Cue * Congruency * Alignment + Probability + 
      (Cue_C + Con_C + Ali_C + 
         Cue_Con +  # Con_Ali + Cue_Ali +
         Cue_Con_Ali || Participant),
    data = df_lmm_rt,
    control = lmerControl(optimizer = "optimx", # calc.derivs = FALSE,
                          optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE))
  )
  # save(glmm_rt_rdc, file = file_rt_rdc)
} else {
  load(file_rt_rdc)
}

print(summary(glmm_rt_rdc), corr = FALSE)
```

#### The extended model
```{r rt exteded model glmm_rt_etd}
file_rt_etd <- file.path(folder_lmm, "rt_lmm_etd.RData")

# fit the etd model
if (!file.exists(file_rt_etd)) {
   glmm_rt_etd <- lmer(
    log(RT) ~ Cue * Congruency * Alignment + Probability + 
      (Cue_C + Con_C + Ali_C + 
         Cue_Con +  # Con_Ali + Cue_Ali +
         Cue_Con_Ali | Participant),
    data = df_lmm_rt,
    control = lmerControl(optimizer = "optimx", # calc.derivs = FALSE,
                          optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE))
  )
  # save(glmm_rt_etd, file = glmm_rt_etd)
} else {
  load(file_rt_etd)
}

print(summary(glmm_rt_etd), corr = FALSE)
```

```{r rt exteded1 model}
file_rt_etd1 <- file.path(folder_lmm, "rt_lmm_etd1.RData")

# fit the etd1 model
if (!file.exists(file_rt_etd1)) {
  ss <- getME(glmm_rt_etd, c("theta","fixef"))
  glmm_rt_etd1 <- update(
    glmm_rt_etd, start=ss,
    control=lmerControl(optimizer = "optimx", # calc.derivs = FALSE,
                         optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE)))
} else {
  load(file_rt_etd1)
}

print(summary(glmm_rt_etd1), corr = FALSE)
```


```{r rePCA for glmm_rt_etd1}
summary(rePCA(glmm_rt_etd1))
```

`Con_C` and `Ali_C` were removed from extended model (`glmm_resp_etd1`) due to that the variances they explained were smaller than 1%, making `glmm_resp_etd2`.

```{r rt exteded model glmm_rt_etd2}
file_rt_etd2 <- file.path(folder_lmm, "rt_lmm_etd2.RData")

# fit the etd2 model
if (!file.exists(file_rt_etd2)) {
  glmm_rt_etd2 <- lmer(
    log(RT) ~ Cue * Congruency * Alignment + Probability + 
      (Cue_C + # Con_C + Ali_C + 
         Cue_Con +  # Con_Ali + Cue_Ali +
         Cue_Con_Ali | Participant),
    data = df_lmm_rt,
    control = lmerControl(optimizer = "optimx", # calc.derivs = FALSE,
                          optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE))
  )
  # save(glmm_rt_etd2, file = file_rt_etd2)
} else {
  load(file_rt_etd2)
}

print(summary(glmm_rt_etd2), corr = FALSE)
```

#### The optimal model
```{r comapre rt etd and rdc}
# compare the extended and reduced model
anova(glmm_rt_etd2, glmm_rt_rdc, refit = FALSE)
```

According to BIC, the reduced model (`glmm_resp_rdc`) explained the data better than the extended model (`glmm_resp_etd2`) and, therefore, the reduced model is used as the optimal model.

```{r the optimal model rt}
glmm_rt_opt <- glmm_rt_rdc

print(summary(glmm_rt_opt), corr = FALSE)
```

### Estimated marginal means
#### Estimated marginal means for RT
```{r emm rt}
file_rt_emm <- file.path(folder_lmm, "rt_emm.RData") 
if (!file.exists(file_rt_emm)) {
  emm_rt <- emmeans(glmm_rt_opt, ~ Cue + Congruency + Alignment)
} else {
  load(file_rt_emm)
}

summary(emm_rt, type = "response") # equivalent to regrid(emm_rt)
```

```{r}
emmip(regrid(emm_rt), Congruency ~ Alignment | Cue, CIs = TRUE)
```

```{r plot for publication E12 rt slides, fig.width=5, fig.asp=.6}
plot_E12_cf_rt <- summary(emm_rt, type = "response") %>% 
  as_tibble() %>% 
  ggplot(aes(y = response, x = Alignment, color = Congruency, group = Congruency)) +
  geom_point(position = position_dodge(width = 0.1), size = 2) +
  geom_line(aes(linetype = Congruency), position = position_dodge(width = 0.1),
            size = 0.8) +
  scale_linetype_manual(values=c("solid", "dashed"))+
  geom_errorbar(aes(ymin = asymp.LCL, ymax = asymp.UCL), size=1.5, width=0, 
                alpha = .6, position = position_dodge(width = 0.1),
                show.legend = F) + 
  facet_grid(. ~Cue, switch = "both") +
  coord_cartesian(ylim = ylimit_cf_rt) +  # set the limit for y axis c(0, 1100)
  labs(x = "Cues", y = "Correct response times (ms)", fill = "Congruency") +  # set the names for main, x and y axises
  geom_text(label = c("", "", "***", "***", "", "", "", ""), color = "red", size = 6, nudge_y = 50, nudge_x = 0.5) + # add starts to the significant columns
  theme_bw() +
  theme(
    text = element_text(size = 10),
    axis.title = element_text(size = 16), 
    axis.text = element_text(size = 14), # the size of the texts in plot
    # axis.text.x = element_text(angle = 45, vjust = 0.5),
    legend.title=element_text(size=15),
    legend.text=element_text(size=14),
    legend.position = "right",
    legend.key.width = unit(1.2, "cm"),
    plot.title = element_text(lineheight=.8, face="bold", size = 17),
    panel.border = element_blank(),
    panel.grid.minor = element_blank(),
    panel.grid.major = element_blank(),
    axis.line.x = element_line(colour = 'black', size=0.5, linetype='solid'),
    axis.line.y = element_line(colour = 'black', size=0.5, linetype='solid'),
    # remove the facet background color
    strip.text = element_text(face="bold", size=14, lineheight=5.0),
    strip.background = element_rect(fill="white", colour="white", size=1),
    strip.placement = "outside"
  ) 

# ggsave(filename = "E12_cf_rt.pdf", plot_E12_cf_rt, width = 8, height = 4.8)

plot_E12_cf_rt
```


#### Composite effects
Composite face effects for top and bottom parts:
```{r}
emm_rt_cf <- contrast(regrid(emm_rt), interaction = "pairwise", by = "Cue", infer = TRUE)
emm_rt_cf[1:2]
```

```{r message=FALSE}
emmip(emm_rt_cf[1:2], ~ Cue , CIs = TRUE) +
  geom_hline(yintercept = 0, linetype = "dashed")
```


#### Facilitation and interference
```{r}
emm_rt_fi <- contrast(regrid(emm_rt), "pairwise", by = c("Cue", "Congruency"), infer=TRUE, adjust = "Tukey")
emm_rt_fi[1:4]
```

```{r message=FALSE}
emmip(emm_rt_fi[1:4], ~ Cue | Congruency, CIs = TRUE, adjust = "Tukey") +
  geom_hline(yintercept = 0, linetype = "dashed")
```

```{r fi E12 rt, fig.width=3, fig.asp=.65}
plot_E12_cffi_rt <- emm_rt_fi[1:4] %>% 
  as_tibble() %>% 
  ggplot(aes(y = estimate, x = Cue, color = Congruency)) +
  geom_point(size = 2) +
  geom_errorbar(aes(ymin = asymp.LCL, ymax = asymp.UCL), size=1.5, width=0, 
                alpha = .6) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  facet_grid(. ~ Congruency, switch = "both") +
  coord_cartesian(ylim = ylimit_cf_fi_rt) +  # set the limit for y axis c(0, 1100)
  labs(x = "Congruency", y = expression(RT~"(aligned-misaligned)")) +  # set the names for main, x and y axises
  theme_bw() +
  theme(
    text = element_text(size = 10),
    axis.title = element_text(size = 16), 
    axis.text = element_text(size = 14), # the size of the texts in plot
    # axis.text.x = element_text(angle = 45, vjust = 0.5),
    legend.title=element_text(size=15),
    legend.text=element_text(size=14),
    legend.position = "none",
    legend.key.width = unit(1.2, "cm"),
    plot.title = element_text(lineheight=.8, face="bold", size = 17),
    panel.border = element_blank(),
    panel.grid.minor = element_blank(),
    panel.grid.major = element_blank(),
    axis.line.x = element_line(colour = 'black', size=0.5, linetype='solid'),
    axis.line.y = element_line(colour = 'black', size=0.5, linetype='solid'),
    # remove the facet background color
    strip.text = element_text(face="bold", size=14, lineheight=5.0),
    strip.background = element_rect(fill="white", colour="white", size=1),
    strip.placement = "outside"
  ) +
  NULL

# ggsave(filename = "E12_fi_rt.pdf", plot_E12_cffi_rt, width = 7, height = 4.55)

plot_E12_cffi_rt
```

#### Comparisons between facilitation and interference

```{r}
summary(contrast(emm_rt_fi, method = list("faci-inte"=c(1, 1)), by = "Cue"), infer = TRUE)
```

```{r}
emmeans(regrid(emm_rt), ~ Alignment | Cue) %>% 
  # regrid() %>% 
  contrast(interaction = "pairwise") %>% 
  summary(infer = TRUE)
```

## Response times with same trials only
```{r only keep correct "same incongruent" trials}
df_lmm_rt_scf <- df_lmm_rt %>% 
  filter(SameDifferent == "same",
         Congruency == "incongruent")

# save(df_lmm_rt_scf, file = file.path("data", "df_lmm_rt_scf.RData"))
```

### Fitting the generalized mixed models
with log-transformation.
#### The maximal model
```{r rt scf max}
# file_rt_scf_max <- file.path(folder_lmm, "rt_scf_lmm_max.RData")
# 
# # fit the max model
# if (!file.exists(file_rt_scf_max)) {
#   glmm_rt_scf_max <- glmer(
#     log(RT) ~ Cue * Alignment + Probability +
#       (Cue * Alignment | Participant), 
#     family = lognormal(),
#     data = df_lmm_rt_scf,
#     control = glmerControl(optimizer = "optimx", # calc.derivs = FALSE,
#                            optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE))
#   )
# 
#   save(glmm_rt_scf_max, file = file_rt_scf_max)
# } else {
#   load(file_rt_scf_max)
# }
# 
# print(summary(glmm_rt_scf_max), corr = FALSE)

```


#### The zero-correlation-parameter model
```{r rt_scf zcp}

file_rt_scf_zcp <- file.path(folder_lmm, "rt_scf_lmm_zcp.RData")

# fit the zcp1 model
if (!file.exists(file_rt_scf_zcp)) {
  glmm_rt_scf_zcp <- lmer(
    log(RT) ~ Cue * Alignment + Probability + 
      (Cue_C + Ali_C + 
         Cue_Ali || Participant),
    data = df_lmm_rt_scf,
    control = lmerControl(optimizer = "optimx", # calc.derivs = FALSE,
                          optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE))
  )
    # save(glmm_rt_scf_zcp, file = file_rt_scf_zcp)
} else {
    load(file_rt_scf_zcp)
}

print(summary(glmm_rt_scf_zcp), corr = FALSE)

```

#### The reduced model
```{r PCA analysis for rt scf zcp lmm}
summary(rePCA(glmm_rt_scf_zcp))
```

```{r rt_scf rdc}
file_rt_scf_rdc <- file.path(folder_lmm, "rt_scf_lmm_rdc.RData")

# fit the rdc model
if (!file.exists(file_rt_scf_rdc)) {
  glmm_rt_scf_rdc <- lmer(
    log(RT) ~ Cue * Alignment + Probability + 
      (Cue_C + # Ali_C + 
         Cue_Ali || Participant),
    data = df_lmm_rt_scf,
    control = lmerControl(optimizer = "optimx", # calc.derivs = FALSE,
                          optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE))
  )
    # save(glmm_rt_scf_rdc, file = file_rt_scf_rdc)
} else {
    load(file_rt_scf_rdc)
}

print(summary(glmm_rt_scf_rdc), corr = FALSE)

```

#### The extended model
```{r rt_scf etd}
file_rt_scf_etd <- file.path(folder_lmm, "rt_scf_lmm_etd.RData")

# fit the etd model
if (!file.exists(file_rt_scf_etd)) {
  glmm_rt_scf_etd <- lmer(
    log(RT) ~ Cue * Alignment + Probability + 
      (Cue_C + # Ali_C + 
         Cue_Ali | Participant),
    data = df_lmm_rt_scf,
    control = lmerControl(optimizer = "optimx", # calc.derivs = FALSE,
                          optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE))
  )
    # save(glmm_rt_scf_etd, file = file_rt_scf_etd)
} else {
    load(file_rt_scf_etd)
}

print(summary(glmm_rt_scf_etd), corr = FALSE)
# save(glmm_rt_scf_etd, file = file.path("lmm_output", "rt_scf_lmm_etd.RData"))
```

#### The optimal model
```{r comapre rt scf etd and rdc}
# compare the extended and reduced model
anova(glmm_rt_scf_etd, glmm_rt_scf_rdc, refit = FALSE)
```

```{r the optimal model rt scf}
glmm_rt_scf_opt <- glmm_rt_scf_etd

print(summary(glmm_rt_scf_opt), corr = FALSE)
```

### Estimated marginal means
```{r emm rt scf}
file_rt_scf_emm <- file.path(folder_lmm, "rt_scf_emm.RData") 
if (!file.exists(file_rt_scf_emm)) {
  emm_rt_scf <- emmeans(glmm_rt_scf_opt, ~ Cue + Alignment, pbkrtest.limit = 10500)
  save(emm_rt_scf)
} else {
  load(file_rt_scf_emm)
}

summary(emm_rt_scf, type = "response") 
```

```{r}
emmip(emm_rt_scf, ~ Alignment | Cue, CIs = TRUE)
```

#### Composite effects
Composite face effects for top and bottom parts:
```{r}
emm_rt_scf_cf <- contrast(regrid(emm_rt_scf), "pairwise", by = "Cue", infer = TRUE)
emm_rt_scf_cf[1:2]
```

```{r message=FALSE}
emmip(emm_rt_scf_cf, ~ Cue, CIs = TRUE) +
  geom_hline(yintercept = 0, linetype = "dashed")
```

# Session information {.unlisted .unnumbered}
```{r}
sessionInfo()
```


